{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pyflakes config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dcf051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Configuration.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
    "\"\"\"Configuration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1144f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n"
<<<<<<< HEAD
=======
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterpartsConfig\n",
      "\n",
      "    general:\n",
      "        log: {level: info, filename: null, filemode: null, format: null, datefmt: null}\n",
      "        outdir: .\n",
      "        n_jobs: 1\n",
      "        datasets_file: null\n",
      "        models_file: null\n",
      "    roi:\n",
      "        target:\n",
      "            name: PSR J1826-1256\n",
      "            position: {frame: icrs, lon: 276.53554166666663 deg, lat: -12.9425 deg}\n",
      "            model:\n",
      "                name: PSR J1826-1256\n",
      "                type: SkyModel\n",
      "                spectral:\n",
      "                    type: ExpCutoffPowerLawSpectralModel\n",
      "                    parameters:\n",
      "                    - {name: index, value: 1.5}\n",
      "                    - {name: amplitude, value: 1.0e-12, unit: TeV-1 s-1 cm-2}\n",
      "                    - {name: reference, value: 1.0, unit: TeV}\n",
      "                    - {name: lambda_, value: 0.1, unit: TeV-1}\n",
      "                    - {name: alpha, value: 1.0}\n",
      "        region_radius: 0.5 deg\n",
      "        energy_range: {min: 0.1 TeV, max: 100.0 TeV}\n",
      "    \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "config must be dict or SimulationConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtarget\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Target\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# from feupy.analysis.simulation.observations import ObservationParameters\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObservationParameters\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Irfs\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeometryParameters\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# from .config import CounterpartsAnalysisConfig, CTAObservationAnalysisConfig, SimulationConfig\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CounterpartsConfig, SimulationConfig\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counterparts, Simulation\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobservations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObservationParameters\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_spectrum_dataset_empty, create_spectrum_dataset_onoff\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:476\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MapAxis\u001b[38;5;241m.\u001b[39mfrom_energy_bounds(        \n\u001b[1;32m    465\u001b[0m             energy_min\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mmin, \n\u001b[1;32m    466\u001b[0m             energy_max\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mmax, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m             name\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[1;32m    482\u001b[0m analysis\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mobservations\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mposition\u001b[38;5;241m.\u001b[39mlat\u001b[38;5;241m.\u001b[39mdeg\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:328\u001b[0m, in \u001b[0;36mSimulation.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_logging()\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_geometry()\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:449\u001b[0m, in \u001b[0;36mSimulation.config\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig must be dict or SimulationConfig.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: config must be dict or SimulationConfig."
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "# from pydantic.v1 import BaseModel\n",
    "# from pydantic.v1.utils import lenient_isinstance\n",
    "from pydantic.utils import deep_update\n",
    "\n",
    "from feupy.roi import ROI\n",
    "from feupy.target import Target\n",
    "\n",
    "# from feupy.analysis.simulation.observations import ObservationParameters\n",
    "from feupy.analysis.simulation import ObservationParameters\n",
    "\n",
    "from feupy.cta.irfs import Irfs\n",
    "from feupy.analysis.simulation import GeometryParameters\n",
    "\n",
    "from feupy.utils.observation import create_observation\n",
    "from feupy.utils.geometry import (\n",
    "    create_energy_axis, \n",
    "    define_on_region, \n",
    "    create_region_geometry\n",
    ")\n",
    "from feupy.plotters import *\n",
    "\n",
    "from feupy.utils.types import (\n",
    "    AngleType,\n",
    "    EnergyType,\n",
    "    QuantityType,\n",
    "    TimeType,\n",
    "    IrfType,\n",
    ")\n",
    "\n",
<<<<<<< HEAD
    "from feupy.utils.enum import(\n",
    "    CatalogsTypeEnum,\n",
=======
    "from feupy.utils.enum import(    \n",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
    "    ReductionTypeEnum,\n",
    "    FrameEnum,\n",
    "    RequiredHDUEnum,\n",
    "    BackgroundMethodEnum,\n",
    "    SafeMaskMethodsEnum,\n",
    "    MapSelectionEnum,\n",
    ")\n",
    "\n",
    "\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.time import Time\n",
    "from astropy.units import Quantity\n",
    "\n",
    "from gammapy.utils.units import energy_unit_format\n",
    "from gammapy.utils.scripts import make_path, read_yaml\n",
    "from gammapy.makers import MapDatasetMaker\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52e393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947422b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __file__ = 'file'\n",
    "# __name__ = 'name'\n",
    "\n",
    "\n",
    "from feupy.utils.scripts import pickling, unpickling\n",
    "from feupy.cta.irfs import Irfs\n",
    "from feupy.catalog.pulsar.atnf import SourceCatalogATNF\n",
    "\n",
    "from feupy.target import Target\n",
    "\n",
    "from feupy.utils.coordinates import skcoord_to_dict, dict_to_skcoord\n",
    "\n",
    "from feupy.analysis.simulation import ObservationParameters\n",
    "\n",
    "from feupy.plotters import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.table import Table\n",
    "\n",
    "from gammapy.modeling.models import SkyModel\n",
    "\n",
    "from gammapy.modeling import Fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb09a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c1ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"CounterpartsConfig\", 'SimulationConfig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(__file__).resolve().parent / \"config\"\n",
    "DOCS_FILE = CONFIG_PATH / \"docs.yaml\"\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04207b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8357e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GammapyBaseConfig(BaseModel):\n",
    "    class Config:\n",
    "        validate_all = True\n",
    "        validate_assignment = True\n",
    "        arbitrary_types_allowed=True\n",
    "        from_attributes=True\n",
    "        extra = \"forbid\"\n",
    "        json_encoders = {\n",
    "            Angle: lambda v: f\"{v.value} {v.unit}\",\n",
    "            Quantity: lambda v: f\"{v.value} {v.unit}\",\n",
    "            Time: lambda v: f\"{v.value}\",\n",
    "        }\n",
    "\n",
    "        \n",
    "class SkyCoordConfig(GammapyBaseConfig):\n",
    "    frame: FrameEnum = None\n",
    "    lon: AngleType = None\n",
    "    lat: AngleType = None\n",
    "\n",
    "        \n",
    "class EnergyAxisConfig(GammapyBaseConfig):\n",
    "    min: EnergyType = None\n",
    "    max: EnergyType = None\n",
    "    nbins: int = None\n",
    "    name: str = \"energy\"\n",
    "\n",
    "\n",
    "class SpatialCircleConfig(GammapyBaseConfig):\n",
    "    frame: FrameEnum = None\n",
    "    lon: AngleType = None\n",
    "    lat: AngleType = None\n",
    "    radius: AngleType = None\n",
    "\n",
    "\n",
    "class EnergyRangeConfig(GammapyBaseConfig):\n",
    "    min: EnergyType = None\n",
    "    max: EnergyType = None\n",
    "\n",
    "\n",
    "class TimeRangeConfig(GammapyBaseConfig):\n",
    "    start: TimeType = None\n",
    "    stop: TimeType = None\n",
    "\n",
    "\n",
    "class FluxPointsConfig(GammapyBaseConfig):\n",
    "    energy: EnergyAxisConfig = EnergyAxisConfig()\n",
    "    source: str = \"source\"\n",
    "    parameters: dict = {\"selection_optional\": \"all\"}\n",
    "\n",
    "\n",
    "class LightCurveConfig(GammapyBaseConfig):\n",
    "    time_intervals: TimeRangeConfig = TimeRangeConfig()\n",
    "    energy_edges: EnergyAxisConfig = EnergyAxisConfig()\n",
    "    source: str = \"source\"\n",
    "    parameters: dict = {\"selection_optional\": \"all\"}\n",
    "\n",
    "\n",
    "class FitConfig(GammapyBaseConfig):\n",
    "    fit_range: EnergyRangeConfig = EnergyRangeConfig()\n",
    "\n",
    "\n",
    "class ExcessMapConfig(GammapyBaseConfig):\n",
    "    correlation_radius: AngleType = \"0.1 deg\"\n",
    "    parameters: dict = {}\n",
    "    energy_edges: EnergyAxisConfig = EnergyAxisConfig()\n",
    "\n",
    "\n",
    "class BackgroundConfig(GammapyBaseConfig):\n",
    "    method: BackgroundMethodEnum = None\n",
    "    exclusion: Path = None\n",
    "    parameters: dict = {}\n",
    "\n",
    "\n",
    "class SafeMaskConfig(GammapyBaseConfig):\n",
    "    methods: List[SafeMaskMethodsEnum] = [SafeMaskMethodsEnum.aeff_default]\n",
    "    parameters: dict = {}\n",
    "\n",
    "\n",
    "class EnergyAxesConfig(GammapyBaseConfig):\n",
    "    energy: EnergyAxisConfig = EnergyAxisConfig(min=\"1 TeV\", max=\"10 TeV\", nbins=5, name=\"energy\")\n",
    "    energy_true: EnergyAxisConfig = EnergyAxisConfig(\n",
    "        min=\"0.5 TeV\", max=\"20 TeV\", nbins=16, name=\"energy_true\"\n",
    "    )\n",
    "\n",
    "\n",
    "class SelectionConfig(GammapyBaseConfig):\n",
    "    offset_max: AngleType = \"2.5 deg\"\n",
    "\n",
    "\n",
    "class WidthConfig(GammapyBaseConfig):\n",
    "    width: AngleType = \"5 deg\"\n",
    "    height: AngleType = \"5 deg\"\n",
    "\n",
    "\n",
    "class WcsConfig(GammapyBaseConfig):\n",
    "    skydir: SkyCoordConfig = SkyCoordConfig()\n",
    "    binsize: AngleType = \"0.02 deg\"\n",
    "    width: WidthConfig = WidthConfig()\n",
    "    binsize_irf: AngleType = \"0.2 deg\"\n",
    "\n",
    "\n",
    "class GeomConfig(GammapyBaseConfig):\n",
    "#     wcs: WcsConfig = WcsConfig()\n",
    "#     selection: SelectionConfig = SelectionConfig()\n",
    "    axes: EnergyAxesConfig = EnergyAxesConfig()\n",
    "\n",
    "\n",
    "class DatasetsConfig(GammapyBaseConfig):\n",
<<<<<<< HEAD
    "    type: ReductionTypeEnum = ReductionTypeEnum.spectrum\n",
=======
    "#     type: ReductionTypeEnum = ReductionTypeEnum.spectrum\n",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
    "#     stack: bool = True\n",
    "    geom: GeomConfig = GeomConfig()\n",
    "    selection: List[MapSelectionEnum] = MapDatasetMaker.available_selection\n",
    "    use_region_center: bool = False\n",
    "#     background: BackgroundConfig = BackgroundConfig()\n",
<<<<<<< HEAD
=======
    "    safe_mask: SafeMaskConfig = SafeMaskConfig()\n",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
    "#     on_region: SpatialCircleConfig = SpatialCircleConfig()\n",
    "    containment_correction: bool = False\n",
    "    safe_mask: SafeMaskConfig = SafeMaskConfig()\n",
    "        \n",
    "\n",
    "class DatasetsOnOffConfig(GammapyBaseConfig):\n",
    "    acceptance: int = None\n",
    "    acceptance_off: int = None\n",
    "    alpha: float = None\n",
    "        \n",
    "        \n",
    "class SensitivityConfig(GammapyBaseConfig):\n",
    "    gamma_min: int = None\n",
    "    n_sigma: int = None\n",
    "    bkg_syst_fraction: float = None\n",
    "\n",
    "                \n",
    "class ObservationsParametersConfig(GammapyBaseConfig):\n",
    "    livetime: QuantityType = None\n",
    "    offset: QuantityType = None\n",
    "    on_region_radius: AngleType = None\n",
    "    n_obs: int = None\n",
    "\n",
    "\n",
    "class TargetConfig(GammapyBaseConfig):\n",
    "    name: str = None\n",
    "    position: SkyCoordConfig = SkyCoordConfig()\n",
<<<<<<< HEAD
    "    model: dict = {}  \n",
=======
    "    model:  dict = {}  \n",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
    "        \n",
    "class IrfsConfig(GammapyBaseConfig):\n",
    "    opt: IrfType = ['South', 'AverageAz', '20deg', '50h']\n",
    "\n",
    "class PointingConfig(GammapyBaseConfig):\n",
    "    angle: AngleType = None\n",
    "        \n",
    "class IrfsConfig(GammapyBaseConfig):\n",
    "    opt: IrfType = ['South', 'AverageAz', '20deg', '50h']\n",
    "\n",
    "        \n",
    "class PointingConfig(GammapyBaseConfig):\n",
    "    angle: AngleType = 0 * u.deg\n",
    "        \n",
    "class ObservationsConfig(GammapyBaseConfig):\n",
    "    target: TargetConfig = TargetConfig()\n",
    "    parameters: ObservationsParametersConfig = ObservationsParametersConfig()\n",
    "    irfs: IrfsConfig = IrfsConfig()\n",
    "    pointing: PointingConfig = PointingConfig()\n",
    "        \n",
    "class ROIConfig(GammapyBaseConfig):\n",
    "    target: TargetConfig = TargetConfig()\n",
<<<<<<< HEAD
    "    radius: AngleType = None\n",
    "    catalogs: CatalogsTypeEnum = \"all\"\n",
    "    dict_sep: dict = {} \n",
    "    leg_style: dict = {}\n",
=======
    "    region_radius: AngleType = None\n",
    "    \n",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
    "        \n",
    "#     datastore: Path = Path(\"$GAMMAPY_DATA/hess-dl3-dr1/\")\n",
    "#     obs_ids: List[int] = []\n",
    "#     obs_file: Path = None\n",
    "#     obs_cone: SpatialCircleConfig = SpatialCircleConfig()\n",
    "#     obs_time: TimeRangeConfig = TimeRangeConfig()\n",
    "#     required_irf: List[RequiredHDUEnum] = [\"aeff\", \"edisp\", \"psf\", \"bkg\"]\n",
    "\n",
    "\n",
    "class LogConfig(GammapyBaseConfig):\n",
    "    level: str = \"info\"\n",
    "    filename: Path = None\n",
    "    filemode: str = None\n",
    "    format: str = None\n",
    "    datefmt: str = None\n",
    "\n",
    "\n",
    "class GeneralConfig(GammapyBaseConfig):\n",
    "    log: LogConfig = LogConfig()\n",
    "    outdir: str = \".\"\n",
    "    n_jobs: int = 1\n",
    "    datasets_file: Path = None\n",
    "    models_file: Path = None\n",
    "\n",
    "        \n",
<<<<<<< HEAD
    "\n",
    "class GeneralCounterpartsConfig(GammapyBaseConfig):\n",
    "    log: LogConfig = LogConfig()\n",
    "    outdir: str = \".\"\n",
    "    path_file: Path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e80793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterpartsConfig(GammapyBaseConfig):\n",
    "    \"\"\"Gammapy analysis configuration.\"\"\"\n",
    "\n",
    "    general: GeneralCounterpartsConfig = GeneralCounterpartsConfig()\n",
    "    roi: ROIConfig = ROIConfig()\n",
    "    energy_range: EnergyRangeConfig = EnergyRangeConfig()\n",
    "#     irfs: IrfsConfig = IrfsConfig()\n",
    "#     datasets: DatasetsConfig = DatasetsConfig()\n",
    "#     sensitivity: SensitivityConfig = SensitivityConfig()\n",
    "#     fit: FitConfig = FitConfig()\n",
    "#     flux_points: FluxPointsConfig = FluxPointsConfig()\n",
    "#     excess_map: ExcessMapConfig = ExcessMapConfig()\n",
    "#     light_curve: LightCurveConfig = LightCurveConfig()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display settings in pretty YAML format.\"\"\"\n",
    "        info = self.__class__.__name__ + \"\\n\\n\\t\"\n",
    "        data = self.to_yaml()\n",
    "        data = data.replace(\"\\n\", \"\\n\\t\")\n",
    "        info += data\n",
    "        return info.expandtabs(tabsize=4)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path):\n",
    "        \"\"\"Reads from YAML file.\"\"\"\n",
    "        config = read_yaml(path)\n",
    "        return CounterpartsConfig(**config)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, config_str):\n",
    "        \"\"\"Create from YAML string.\"\"\"\n",
    "        settings = yaml.safe_load(config_str)\n",
    "        return CounterpartsConfig(**settings)\n",
    "\n",
    "\n",
    "    def write(self, path = None, overwrite=False):\n",
    "        \"\"\"Write to YAML file.\"\"\"\n",
    "        if path is not None:\n",
    "            path = make_path(path)\n",
    "        else: path = make_path(f\"{self.general.path_file}/counterparts_config.yaml\")\n",
    "            \n",
    "        if path.exists() and not overwrite:\n",
    "            raise IOError(f\"File exists already: {path}\")\n",
    "        path.write_text(self.to_yaml())\n",
    "\n",
    "\n",
    "    def to_yaml(self):\n",
    "        \"\"\"Convert to YAML string.\"\"\"\n",
    "        # Here using `dict()` instead of `json()` would be more natural.\n",
    "        # We should change this once pydantic adds support for custom encoders\n",
    "        # to `dict()`. See https://github.com/samuelcolvin/pydantic/issues/1043\n",
    "        config = json.loads(self.json())\n",
    "        return yaml.dump(\n",
    "            config, sort_keys=False, indent=4, width=80, default_flow_style=None\n",
    "        )\n",
    "\n",
    "    def set_logging(self):\n",
    "        \"\"\"Set logging config.\n",
    "\n",
    "        Calls ``logging.basicConfig``, i.e. adjusts global logging state.\n",
    "        \"\"\"\n",
    "        self.general.log.level = self.general.log.level.upper()\n",
    "        logging.basicConfig(**self.general.log.dict())\n",
    "        log.info(\"Setting logging config: {!r}\".format(self.general.log.dict()))\n",
    "\n",
    "\n",
    "    def update(self, config=None):\n",
    "        \"\"\"Update config with provided settings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : string dict or `CounterpartsConfig` object\n",
    "            Configuration settings provided in dict() syntax.\n",
    "        \"\"\"\n",
    "        if isinstance(config, str):\n",
    "            other = CounterpartsConfig.from_yaml(config)\n",
    "        elif isinstance(config, CounterpartsConfig):\n",
    "            other = config\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {config}\")\n",
    "\n",
    "        config_new = deep_update(\n",
    "            self.dict(exclude_defaults=True), other.dict(exclude_defaults=True)\n",
    "        )\n",
    "        return CounterpartsConfig(**config_new)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc_sections():\n",
    "        \"\"\"Returns dict with commented docs from docs file\"\"\"\n",
    "        doc = defaultdict(str)\n",
    "        with open(DOCS_FILE) as f:\n",
    "            for line in filter(lambda line: not line.startswith(\"---\"), f):\n",
    "                line = line.strip(\"\\n\")\n",
    "                if line.startswith(\"# Section: \"):\n",
    "                    keyword = line.replace(\"# Section: \", \"\")\n",
    "                doc[keyword] += line + \"\\n\"\n",
    "        return doc    "
=======
    "\n",
    "        \n"
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "6f7631fa",
=======
   "id": "10e80793",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
   "id": "c36d389c",
=======
   "id": "3f66085f",
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationConfig(GammapyBaseConfig):\n",
    "    \"\"\"Gammapy analysis configuration.\"\"\"\n",
    "\n",
    "    general: GeneralConfig = GeneralConfig()\n",
    "    observations: ObservationsConfig = ObservationsConfig()\n",
    "#     irfs: IrfsConfig = IrfsConfig()\n",
    "    datasets: DatasetsConfig = DatasetsConfig()\n",
    "    sensitivity: SensitivityConfig = SensitivityConfig()\n",
    "#     fit: FitConfig = FitConfig()\n",
    "#     flux_points: FluxPointsConfig = FluxPointsConfig()\n",
    "#     excess_map: ExcessMapConfig = ExcessMapConfig()\n",
    "#     light_curve: LightCurveConfig = LightCurveConfig()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display settings in pretty YAML format.\"\"\"\n",
    "        info = self.__class__.__name__ + \"\\n\\n\\t\"\n",
    "        data = self.to_yaml()\n",
    "        data = data.replace(\"\\n\", \"\\n\\t\")\n",
    "        info += data\n",
    "        return info.expandtabs(tabsize=4)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path):\n",
    "        \"\"\"Reads from YAML file.\"\"\"\n",
    "        config = read_yaml(path)\n",
    "        return SimulationConfig(**config)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, config_str):\n",
    "        \"\"\"Create from YAML string.\"\"\"\n",
    "        settings = yaml.safe_load(config_str)\n",
    "        return SimulationConfig(**settings)\n",
    "\n",
    "\n",
    "    def write(self, path, overwrite=False):\n",
    "        \"\"\"Write to YAML file.\"\"\"\n",
    "        path = make_path(path)\n",
    "        if path.exists() and not overwrite:\n",
    "            raise IOError(f\"File exists already: {path}\")\n",
    "        path.write_text(self.to_yaml())\n",
    "\n",
    "\n",
    "    def to_yaml(self):\n",
    "        \"\"\"Convert to YAML string.\"\"\"\n",
    "        # Here using `dict()` instead of `json()` would be more natural.\n",
    "        # We should change this once pydantic adds support for custom encoders\n",
    "        # to `dict()`. See https://github.com/samuelcolvin/pydantic/issues/1043\n",
    "        config = json.loads(self.json())\n",
    "        return yaml.dump(\n",
    "            config, sort_keys=False, indent=4, width=80, default_flow_style=None\n",
    "        )\n",
    "\n",
    "    def set_logging(self):\n",
    "        \"\"\"Set logging config.\n",
    "\n",
    "        Calls ``logging.basicConfig``, i.e. adjusts global logging state.\n",
    "        \"\"\"\n",
    "        self.general.log.level = self.general.log.level.upper()\n",
    "        logging.basicConfig(**self.general.log.dict())\n",
    "        log.info(\"Setting logging config: {!r}\".format(self.general.log.dict()))\n",
    "\n",
    "\n",
    "    def update(self, config=None):\n",
    "        \"\"\"Update config with provided settings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : string dict or `SimulationConfig` object\n",
    "            Configuration settings provided in dict() syntax.\n",
    "        \"\"\"\n",
    "        if isinstance(config, str):\n",
    "            other = SimulationConfig.from_yaml(config)\n",
    "        elif isinstance(config, SimulationConfig):\n",
    "            other = config\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {config}\")\n",
    "\n",
    "        config_new = deep_update(\n",
    "            self.dict(exclude_defaults=True), other.dict(exclude_defaults=True)\n",
    "        )\n",
    "        return SimulationConfig(**config_new)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc_sections():\n",
    "        \"\"\"Returns dict with commented docs from docs file\"\"\"\n",
    "        doc = defaultdict(str)\n",
    "        with open(DOCS_FILE) as f:\n",
    "            for line in filter(lambda line: not line.startswith(\"---\"), f):\n",
    "                line = line.strip(\"\\n\")\n",
    "                if line.startswith(\"# Section: \"):\n",
    "                    keyword = line.replace(\"# Section: \", \"\")\n",
    "                doc[keyword] += line + \"\\n\"\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
<<<<<<< HEAD
=======
   "id": "675cd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterpartsConfig(GammapyBaseConfig):\n",
    "    \"\"\"Gammapy analysis configuration.\"\"\"\n",
    "\n",
    "    general: GeneralConfig = GeneralConfig()\n",
    "    roi: ROIConfig = ROIConfig()\n",
    "    energy_range: EnergyRangeConfig = EnergyRangeConfig()\n",
    "#     irfs: IrfsConfig = IrfsConfig()\n",
    "#     datasets: DatasetsConfig = DatasetsConfig()\n",
    "#     sensitivity: SensitivityConfig = SensitivityConfig()\n",
    "#     fit: FitConfig = FitConfig()\n",
    "#     flux_points: FluxPointsConfig = FluxPointsConfig()\n",
    "#     excess_map: ExcessMapConfig = ExcessMapConfig()\n",
    "#     light_curve: LightCurveConfig = LightCurveConfig()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display settings in pretty YAML format.\"\"\"\n",
    "        info = self.__class__.__name__ + \"\\n\\n\\t\"\n",
    "        data = self.to_yaml()\n",
    "        data = data.replace(\"\\n\", \"\\n\\t\")\n",
    "        info += data\n",
    "        return info.expandtabs(tabsize=4)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path):\n",
    "        \"\"\"Reads from YAML file.\"\"\"\n",
    "        config = read_yaml(path)\n",
    "        return CounterpartsConfig(**config)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, config_str):\n",
    "        \"\"\"Create from YAML string.\"\"\"\n",
    "        settings = yaml.safe_load(config_str)\n",
    "        return CounterpartsConfig(**settings)\n",
    "\n",
    "\n",
    "    def write(self, path, overwrite=False):\n",
    "        \"\"\"Write to YAML file.\"\"\"\n",
    "        path = make_path(path)\n",
    "        if path.exists() and not overwrite:\n",
    "            raise IOError(f\"File exists already: {path}\")\n",
    "        path.write_text(self.to_yaml())\n",
    "\n",
    "\n",
    "    def to_yaml(self):\n",
    "        \"\"\"Convert to YAML string.\"\"\"\n",
    "        # Here using `dict()` instead of `json()` would be more natural.\n",
    "        # We should change this once pydantic adds support for custom encoders\n",
    "        # to `dict()`. See https://github.com/samuelcolvin/pydantic/issues/1043\n",
    "        config = json.loads(self.json())\n",
    "        return yaml.dump(\n",
    "            config, sort_keys=False, indent=4, width=80, default_flow_style=None\n",
    "        )\n",
    "\n",
    "    def set_logging(self):\n",
    "        \"\"\"Set logging config.\n",
    "\n",
    "        Calls ``logging.basicConfig``, i.e. adjusts global logging state.\n",
    "        \"\"\"\n",
    "        self.general.log.level = self.general.log.level.upper()\n",
    "        logging.basicConfig(**self.general.log.dict())\n",
    "        log.info(\"Setting logging config: {!r}\".format(self.general.log.dict()))\n",
    "\n",
    "\n",
    "    def update(self, config=None):\n",
    "        \"\"\"Update config with provided settings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : string dict or `CounterpartsConfig` object\n",
    "            Configuration settings provided in dict() syntax.\n",
    "        \"\"\"\n",
    "        if isinstance(config, str):\n",
    "            other = CounterpartsConfig.from_yaml(config)\n",
    "        elif isinstance(config, CounterpartsConfig):\n",
    "            other = config\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {config}\")\n",
    "\n",
    "        config_new = deep_update(\n",
    "            self.dict(exclude_defaults=True), other.dict(exclude_defaults=True)\n",
    "        )\n",
    "        return CounterpartsConfig(**config_new)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc_sections():\n",
    "        \"\"\"Returns dict with commented docs from docs file\"\"\"\n",
    "        doc = defaultdict(str)\n",
    "        with open(DOCS_FILE) as f:\n",
    "            for line in filter(lambda line: not line.startswith(\"---\"), f):\n",
    "                line = line.strip(\"\\n\")\n",
    "                if line.startswith(\"# Section: \"):\n",
    "                    keyword = line.replace(\"# Section: \", \"\")\n",
    "                doc[keyword] += line + \"\\n\"\n",
    "        return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7631fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
>>>>>>> a87345340991221f525a5055c22311aa60793eeb
   "id": "fc70f15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
