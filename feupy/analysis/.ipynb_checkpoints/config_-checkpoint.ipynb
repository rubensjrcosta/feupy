{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pyflakes config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9dcf051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Configuration.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
    "\"\"\"Configuration.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1144f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from pydantic.v1 import BaseModel\n",
    "from pydantic.v1.utils import lenient_isinstance\n",
    "from pydantic.utils import deep_update\n",
    "\n",
    "from feupy.roi import ROI\n",
    "from feupy.target import Target\n",
    "\n",
    "# from feupy.analysis.simulation.observations import ObservationParameters\n",
    "from feupy.analysis.simulation import ObservationParameters\n",
    "\n",
    "from feupy.cta.irfs import Irfs\n",
    "from feupy.analysis.simulation import GeometryParameters\n",
    "\n",
    "from feupy.utils.observation import create_observation\n",
    "from feupy.utils.geometry import (\n",
    "    create_energy_axis, \n",
    "    define_on_region, \n",
    "    create_region_geometry\n",
    ")\n",
    "from feupy.plotters import *\n",
    "\n",
    "from feupy.utils.types import (\n",
    "    AngleType,\n",
    "    EnergyType,\n",
    "    QuantityType,\n",
    "    TimeType,\n",
    "    IrfType,\n",
    ")\n",
    "\n",
    "from feupy.utils.enum import(\n",
    "    CatalogsTypeEnum,\n",
    "    ReductionTypeEnum,\n",
    "    FrameEnum,\n",
    "    RequiredHDUEnum,\n",
    "    BackgroundMethodEnum,\n",
    "    SafeMaskMethodsEnum,\n",
    "    MapSelectionEnum,\n",
    ")\n",
    "\n",
    "\n",
    "from astropy.coordinates import Angle\n",
    "from astropy.time import Time\n",
    "from astropy.units import Quantity\n",
    "\n",
    "from gammapy.utils.units import energy_unit_format\n",
    "from gammapy.utils.scripts import make_path, read_yaml\n",
    "from gammapy.makers import MapDatasetMaker\n",
    "\n",
    "import json\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c52e393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947422b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e5496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __file__ = 'file'\n",
    "# __name__ = 'name'\n",
    "\n",
    "\n",
    "from feupy.utils.scripts import pickling, unpickling\n",
    "from feupy.cta.irfs import Irfs\n",
    "from feupy.catalog.pulsar.atnf import SourceCatalogATNF\n",
    "\n",
    "from feupy.target import Target\n",
    "\n",
    "from feupy.utils.coordinates import skcoord_to_dict, dict_to_skcoord\n",
    "\n",
    "from feupy.analysis.simulation import ObservationParameters\n",
    "\n",
    "from feupy.plotters import *\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.table import Table\n",
    "\n",
    "from gammapy.modeling.models import SkyModel\n",
    "\n",
    "from gammapy.modeling import Fit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb09a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979c1ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"CounterpartsConfig\", 'SimulationConfig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(__file__).resolve().parent / \"config\"\n",
    "DOCS_FILE = CONFIG_PATH / \"docs.yaml\"\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c04207b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8357e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GammapyBaseConfig(BaseModel):\n",
    "    class Config:\n",
    "        validate_all = True\n",
    "        validate_assignment = True\n",
    "        arbitrary_types_allowed=True\n",
    "        from_attributes=True\n",
    "        extra = \"forbid\"\n",
    "        json_encoders = {\n",
    "            Angle: lambda v: f\"{v.value} {v.unit}\",\n",
    "            Quantity: lambda v: f\"{v.value} {v.unit}\",\n",
    "            Time: lambda v: f\"{v.value}\",\n",
    "        }\n",
    "\n",
    "        \n",
    "class SkyCoordConfig(GammapyBaseConfig):\n",
    "    frame: FrameEnum = None\n",
    "    lon: AngleType = None\n",
    "    lat: AngleType = None\n",
    "\n",
    "        \n",
    "class EnergyAxisConfig(GammapyBaseConfig):\n",
    "    min: EnergyType = None\n",
    "    max: EnergyType = None\n",
    "    nbins: int = None\n",
    "    name: str = \"energy\"\n",
    "\n",
    "\n",
    "class SpatialCircleConfig(GammapyBaseConfig):\n",
    "    frame: FrameEnum = None\n",
    "    lon: AngleType = None\n",
    "    lat: AngleType = None\n",
    "    radius: AngleType = None\n",
    "\n",
    "\n",
    "class EnergyRangeConfig(GammapyBaseConfig):\n",
    "    min: EnergyType = None\n",
    "    max: EnergyType = None\n",
    "\n",
    "\n",
    "class TimeRangeConfig(GammapyBaseConfig):\n",
    "    start: TimeType = None\n",
    "    stop: TimeType = None\n",
    "\n",
    "\n",
    "class FluxPointsConfig(GammapyBaseConfig):\n",
    "    energy: EnergyAxisConfig = EnergyAxisConfig()\n",
    "    source: str = \"source\"\n",
    "    parameters: dict = {\"selection_optional\": \"all\"}\n",
    "\n",
    "\n",
    "class LightCurveConfig(GammapyBaseConfig):\n",
    "    time_intervals: TimeRangeConfig = TimeRangeConfig()\n",
    "    energy_edges: EnergyAxisConfig = EnergyAxisConfig()\n",
    "    source: str = \"source\"\n",
    "    parameters: dict = {\"selection_optional\": \"all\"}\n",
    "\n",
    "\n",
    "class FitConfig(GammapyBaseConfig):\n",
    "    fit_range: EnergyRangeConfig = EnergyRangeConfig()\n",
    "\n",
    "\n",
    "class ExcessMapConfig(GammapyBaseConfig):\n",
    "    correlation_radius: AngleType = \"0.1 deg\"\n",
    "    parameters: dict = {}\n",
    "    energy_edges: EnergyAxisConfig = EnergyAxisConfig()\n",
    "\n",
    "\n",
    "class BackgroundConfig(GammapyBaseConfig):\n",
    "    method: BackgroundMethodEnum = None\n",
    "    exclusion: Path = None\n",
    "    parameters: dict = {}\n",
    "\n",
    "\n",
    "class SafeMaskConfig(GammapyBaseConfig):\n",
    "    methods: List[SafeMaskMethodsEnum] = [SafeMaskMethodsEnum.aeff_default]\n",
    "    parameters: dict = {}\n",
    "\n",
    "\n",
    "class EnergyAxisTrueConfig(GammapyBaseConfig):\n",
    "    min: EnergyType = None\n",
    "    max: EnergyType = None\n",
    "    nbins: int = None\n",
    "    name: str = \"energy_true\"\n",
    "        \n",
    "\n",
    "class EnergyAxesConfig(GammapyBaseConfig):\n",
    "    energy: EnergyAxisConfig = EnergyAxisConfig()\n",
    "    energy_true: EnergyAxisTrueConfig = EnergyAxisTrueConfig()\n",
    "\n",
    "\n",
    "class SelectionConfig(GammapyBaseConfig):\n",
    "    offset_max: AngleType = \"2.5 deg\"\n",
    "\n",
    "\n",
    "class WidthConfig(GammapyBaseConfig):\n",
    "    width: AngleType = \"5 deg\"\n",
    "    height: AngleType = \"5 deg\"\n",
    "\n",
    "\n",
    "class WcsConfig(GammapyBaseConfig):\n",
    "    skydir: SkyCoordConfig = SkyCoordConfig()\n",
    "    binsize: AngleType = \"0.02 deg\"\n",
    "    width: WidthConfig = WidthConfig()\n",
    "    binsize_irf: AngleType = \"0.2 deg\"\n",
    "\n",
    "\n",
    "class GeomConfig(GammapyBaseConfig):\n",
    "#     wcs: WcsConfig = WcsConfig()\n",
    "#     selection: SelectionConfig = SelectionConfig()\n",
    "    axes: EnergyAxesConfig = EnergyAxesConfig()\n",
    "\n",
    "\n",
    "class DatasetsConfig(GammapyBaseConfig):\n",
    "    type: ReductionTypeEnum = ReductionTypeEnum.spectrum\n",
    "#     stack: bool = True\n",
    "    geom: GeomConfig = GeomConfig()\n",
    "    selection: List[MapSelectionEnum] = MapDatasetMaker.available_selection\n",
    "    use_region_center: bool = False\n",
    "#     background: BackgroundConfig = BackgroundConfig()\n",
    "#     on_region: SpatialCircleConfig = SpatialCircleConfig()\n",
    "    containment_correction: bool = False\n",
    "    safe_mask: SafeMaskConfig = SafeMaskConfig()\n",
    "        \n",
    "\n",
    "class DatasetsOnOffConfig(GammapyBaseConfig):\n",
    "    acceptance: int = None\n",
    "    acceptance_off: int = None\n",
    "    \n",
    "        \n",
    "        \n",
    "class SensitivityConfig(GammapyBaseConfig):\n",
    "    gamma_min: int = None\n",
    "    n_sigma: int = None\n",
    "    bkg_syst_fraction: float = None\n",
    "    table: dict = {}\n",
    "\n",
    "# class WStatisticsConfig(GammapyBaseConfig):\n",
    "#     excess: float = None\n",
    "#     ts: float = None\n",
    "#     sqrt_ts: float = None\n",
    "\n",
    "class StatisticsConfig(GammapyBaseConfig):\n",
    "    alpha: float = None\n",
    "    wstat: dict = {}\n",
    "    fitted_parameters: dict = {}   \n",
    "                \n",
    "class ObservationsParametersConfig(GammapyBaseConfig):\n",
    "    livetime: QuantityType = None\n",
    "    offset: QuantityType = None\n",
    "    on_region_radius: AngleType = None\n",
    "    n_obs: int = None\n",
    "\n",
    "\n",
    "class TargetConfig(GammapyBaseConfig):\n",
    "    name: str = None\n",
    "    position: SkyCoordConfig = SkyCoordConfig()\n",
    "    model: dict = {}  \n",
    "    model_fitted: dict = {}\n",
    "        \n",
    "class IrfsConfig(GammapyBaseConfig):\n",
    "    opt: IrfType = ['South', 'AverageAz', '20deg', '50h']\n",
    "\n",
    "        \n",
    "class PointingConfig(GammapyBaseConfig):\n",
    "    angle: AngleType = None\n",
    "        \n",
    "class ObservationsConfig(GammapyBaseConfig):\n",
    "    target: TargetConfig = TargetConfig()\n",
    "    parameters: ObservationsParametersConfig = ObservationsParametersConfig()\n",
    "    irfs: IrfsConfig = IrfsConfig()\n",
    "    pointing: PointingConfig = PointingConfig()\n",
    "        \n",
    "class ROIConfig(GammapyBaseConfig):\n",
    "    target: TargetConfig = TargetConfig()\n",
    "    radius: AngleType = None\n",
    "    catalogs: CatalogsTypeEnum = \"all\"\n",
    "    dict_sep: dict = {} \n",
    "    leg_style: dict = {}\n",
    "        \n",
    "#     datastore: Path = Path(\"$GAMMAPY_DATA/hess-dl3-dr1/\")\n",
    "#     obs_ids: List[int] = []\n",
    "#     obs_file: Path = None\n",
    "#     obs_cone: SpatialCircleConfig = SpatialCircleConfig()\n",
    "#     obs_time: TimeRangeConfig = TimeRangeConfig()\n",
    "#     required_irf: List[RequiredHDUEnum] = [\"aeff\", \"edisp\", \"psf\", \"bkg\"]\n",
    "\n",
    "\n",
    "class LogConfig(GammapyBaseConfig):\n",
    "    level: str = \"info\"\n",
    "    filename: Path = None\n",
    "    filemode: str = None\n",
    "    format: str = None\n",
    "    datefmt: str = None\n",
    "\n",
    "\n",
    "class GeneralConfig(GammapyBaseConfig):\n",
    "    log: LogConfig = LogConfig()\n",
    "    outdir: str = \".\"\n",
    "    n_jobs: int = 1\n",
    "    datasets_file: Path = None\n",
    "    models_file: Path = None\n",
    "\n",
    "        \n",
    "\n",
    "class GeneralCounterpartsConfig(GammapyBaseConfig):\n",
    "    log: LogConfig = LogConfig()\n",
    "    outdir: str = \".\"\n",
    "    path_file: Path = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e80793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cd313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterpartsConfig(GammapyBaseConfig):\n",
    "    \"\"\"Gammapy analysis configuration.\"\"\"\n",
    "\n",
    "    general: GeneralCounterpartsConfig = GeneralCounterpartsConfig()\n",
    "    roi: ROIConfig = ROIConfig()\n",
    "    energy_range: EnergyRangeConfig = EnergyRangeConfig()\n",
    "#     irfs: IrfsConfig = IrfsConfig()\n",
    "#     datasets: DatasetsConfig = DatasetsConfig()\n",
    "#     sensitivity: SensitivityConfig = SensitivityConfig()\n",
    "#     fit: FitConfig = FitConfig()\n",
    "#     flux_points: FluxPointsConfig = FluxPointsConfig()\n",
    "#     excess_map: ExcessMapConfig = ExcessMapConfig()\n",
    "#     light_curve: LightCurveConfig = LightCurveConfig()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display settings in pretty YAML format.\"\"\"\n",
    "        info = self.__class__.__name__ + \"\\n\\n\\t\"\n",
    "        data = self.to_yaml()\n",
    "        data = data.replace(\"\\n\", \"\\n\\t\")\n",
    "        info += data\n",
    "        return info.expandtabs(tabsize=4)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path):\n",
    "        \"\"\"Reads from YAML file.\"\"\"\n",
    "        config = read_yaml(path)\n",
    "        return CounterpartsConfig(**config)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, config_str):\n",
    "        \"\"\"Create from YAML string.\"\"\"\n",
    "        settings = yaml.safe_load(config_str)\n",
    "        return CounterpartsConfig(**settings)\n",
    "\n",
    "\n",
    "    def write(self, path = None, overwrite=False):\n",
    "        \"\"\"Write to YAML file.\"\"\"\n",
    "        if path is not None:\n",
    "            path = make_path(path)\n",
    "        else: path = make_path(f\"{self.general.path_file}/counterparts_config.yaml\")\n",
    "            \n",
    "        if path.exists() and not overwrite:\n",
    "            raise IOError(f\"File exists already: {path}\")\n",
    "        path.write_text(self.to_yaml())\n",
    "\n",
    "\n",
    "    def to_yaml(self):\n",
    "        \"\"\"Convert to YAML string.\"\"\"\n",
    "        # Here using `dict()` instead of `json()` would be more natural.\n",
    "        # We should change this once pydantic adds support for custom encoders\n",
    "        # to `dict()`. See https://github.com/samuelcolvin/pydantic/issues/1043\n",
    "        config = json.loads(self.json())\n",
    "        return yaml.dump(\n",
    "            config, sort_keys=False, indent=4, width=80, default_flow_style=None\n",
    "        )\n",
    "\n",
    "    def set_logging(self):\n",
    "        \"\"\"Set logging config.\n",
    "\n",
    "        Calls ``logging.basicConfig``, i.e. adjusts global logging state.\n",
    "        \"\"\"\n",
    "        self.general.log.level = self.general.log.level.upper()\n",
    "        logging.basicConfig(**self.general.log.dict())\n",
    "        log.info(\"Setting logging config: {!r}\".format(self.general.log.dict()))\n",
    "\n",
    "\n",
    "    def update(self, config=None):\n",
    "        \"\"\"Update config with provided settings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : string dict or `CounterpartsConfig` object\n",
    "            Configuration settings provided in dict() syntax.\n",
    "        \"\"\"\n",
    "        if isinstance(config, str):\n",
    "            other = CounterpartsConfig.from_yaml(config)\n",
    "        elif isinstance(config, CounterpartsConfig):\n",
    "            other = config\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {config}\")\n",
    "\n",
    "        config_new = deep_update(\n",
    "            self.dict(exclude_defaults=True), other.dict(exclude_defaults=True)\n",
    "        )\n",
    "        return CounterpartsConfig(**config_new)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc_sections():\n",
    "        \"\"\"Returns dict with commented docs from docs file\"\"\"\n",
    "        doc = defaultdict(str)\n",
    "        with open(DOCS_FILE) as f:\n",
    "            for line in filter(lambda line: not line.startswith(\"---\"), f):\n",
    "                line = line.strip(\"\\n\")\n",
    "                if line.startswith(\"# Section: \"):\n",
    "                    keyword = line.replace(\"# Section: \", \"\")\n",
    "                doc[keyword] += line + \"\\n\"\n",
    "        return doc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7631fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationConfig(GammapyBaseConfig):\n",
    "    \"\"\"Gammapy analysis configuration.\"\"\"\n",
    "\n",
    "    general: GeneralConfig = GeneralConfig()\n",
    "    observations: ObservationsConfig = ObservationsConfig()\n",
    "    datasets: DatasetsConfig = DatasetsConfig()\n",
    "    datasets_onoff: DatasetsOnOffConfig = DatasetsOnOffConfig()\n",
    "    statistics:StatisticsConfig = StatisticsConfig()\n",
    "    sensitivity: SensitivityConfig = SensitivityConfig()\n",
    "#     fit: FitConfig = FitConfig()\n",
    "    flux_points: FluxPointsConfig = FluxPointsConfig()\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"Display settings in pretty YAML format.\"\"\"\n",
    "        info = self.__class__.__name__ + \"\\n\\n\\t\"\n",
    "        data = self.to_yaml()\n",
    "        data = data.replace(\"\\n\", \"\\n\\t\")\n",
    "        info += data\n",
    "        return info.expandtabs(tabsize=4)\n",
    "\n",
    "    @classmethod\n",
    "    def read(cls, path):\n",
    "        \"\"\"Reads from YAML file.\"\"\"\n",
    "        config = read_yaml(path)\n",
    "        return SimulationConfig(**config)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_yaml(cls, config_str):\n",
    "        \"\"\"Create from YAML string.\"\"\"\n",
    "        settings = yaml.safe_load(config_str)\n",
    "        return SimulationConfig(**settings)\n",
    "\n",
    "\n",
    "    def write(self, path, overwrite=False):\n",
    "        \"\"\"Write to YAML file.\"\"\"\n",
    "        path = make_path(path)\n",
    "        if path.exists() and not overwrite:\n",
    "            raise IOError(f\"File exists already: {path}\")\n",
    "        path.write_text(self.to_yaml())\n",
    "\n",
    "\n",
    "    def to_yaml(self):\n",
    "        \"\"\"Convert to YAML string.\"\"\"\n",
    "        # Here using `dict()` instead of `json()` would be more natural.\n",
    "        # We should change this once pydantic adds support for custom encoders\n",
    "        # to `dict()`. See https://github.com/samuelcolvin/pydantic/issues/1043\n",
    "        config = json.loads(self.json())\n",
    "        return yaml.dump(\n",
    "            config, sort_keys=False, indent=4, width=80, default_flow_style=None\n",
    "        )\n",
    "\n",
    "    def set_logging(self):\n",
    "        \"\"\"Set logging config.\n",
    "\n",
    "        Calls ``logging.basicConfig``, i.e. adjusts global logging state.\n",
    "        \"\"\"\n",
    "        self.general.log.level = self.general.log.level.upper()\n",
    "        logging.basicConfig(**self.general.log.dict())\n",
    "        log.info(\"Setting logging config: {!r}\".format(self.general.log.dict()))\n",
    "\n",
    "\n",
    "    def update(self, config=None):\n",
    "        \"\"\"Update config with provided settings.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        config : string dict or `SimulationConfig` object\n",
    "            Configuration settings provided in dict() syntax.\n",
    "        \"\"\"\n",
    "        if isinstance(config, str):\n",
    "            other = SimulationConfig.from_yaml(config)\n",
    "        elif isinstance(config, SimulationConfig):\n",
    "            other = config\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {config}\")\n",
    "\n",
    "        config_new = deep_update(\n",
    "            self.dict(exclude_defaults=True), other.dict(exclude_defaults=True)\n",
    "        )\n",
    "        return SimulationConfig(**config_new)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_doc_sections():\n",
    "        \"\"\"Returns dict with commented docs from docs file\"\"\"\n",
    "        doc = defaultdict(str)\n",
    "        with open(DOCS_FILE) as f:\n",
    "            for line in filter(lambda line: not line.startswith(\"---\"), f):\n",
    "                line = line.strip(\"\\n\")\n",
    "                if line.startswith(\"# Section: \"):\n",
    "                    keyword = line.replace(\"# Section: \", \"\")\n",
    "                doc[keyword] += line + \"\\n\"\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70f15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
