{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dd3a58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n",
      "/home/born-again/anaconda3/envs/gammapy-1.1/lib/python3.9/site-packages/pydantic/_migration.py:290: UserWarning: `pydantic.utils:deep_update` has been removed. We are importing from `pydantic.v1.utils:deep_update` instead.See the migration guide for more details: https://docs.pydantic.dev/latest/migration/\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CounterpartsConfig\n",
      "\n",
      "    general:\n",
      "        log: {level: info, filename: null, filemode: null, format: null, datefmt: null}\n",
      "        outdir: .\n",
      "        n_jobs: 1\n",
      "        datasets_file: null\n",
      "        models_file: null\n",
      "    roi:\n",
      "        target:\n",
      "            name: PSR J1826-1256\n",
      "            position: {frame: icrs, lon: 276.53554166666663 deg, lat: -12.9425 deg}\n",
      "            model:\n",
      "                name: PSR J1826-1256\n",
      "                type: SkyModel\n",
      "                spectral:\n",
      "                    type: ExpCutoffPowerLawSpectralModel\n",
      "                    parameters:\n",
      "                    - {name: index, value: 1.5}\n",
      "                    - {name: amplitude, value: 1.0e-12, unit: TeV-1 s-1 cm-2}\n",
      "                    - {name: reference, value: 1.0, unit: TeV}\n",
      "                    - {name: lambda_, value: 0.1, unit: TeV-1}\n",
      "                    - {name: alpha, value: 1.0}\n",
      "        region_radius: 0.5 deg\n",
      "        energy_range: {min: 0.1 TeV, max: 100.0 TeV}\n",
      "    \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "config must be dict or SimulationConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 74\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcta\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mirfs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Irfs\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcoordinates\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m skcoord_to_dict, dict_to_skcoord\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CounterpartsConfig, SimulationConfig\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfeupy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcatalog\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# from .config import CounterpartsAnalysisConfig, CTAObservationAnalysisConfig, SimulationConfig\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CounterpartsConfig, SimulationConfig\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counterparts, Simulation\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mobservations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ObservationParameters\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_spectrum_dataset_empty, create_spectrum_dataset_onoff\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:476\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m MapAxis\u001b[38;5;241m.\u001b[39mfrom_energy_bounds(        \n\u001b[1;32m    465\u001b[0m             energy_min\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mmin, \n\u001b[1;32m    466\u001b[0m             energy_max\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mmax, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m             name\u001b[38;5;241m=\u001b[39mconfig_axis_energy\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    470\u001b[0m             )\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;66;03m# In[ ]:\u001b[39;00m\n\u001b[1;32m    482\u001b[0m analysis\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mobservations\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mposition\u001b[38;5;241m.\u001b[39mlat\u001b[38;5;241m.\u001b[39mdeg\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:328\u001b[0m, in \u001b[0;36mSimulation.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config):\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mset_logging()\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgeom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_geometry()\n",
      "File \u001b[0;32m~/Documents/GitHub/feupy/feupy/analysis/core.py:449\u001b[0m, in \u001b[0;36mSimulation.config\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig must be dict or SimulationConfig.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: config must be dict or SimulationConfig."
     ]
    }
   ],
   "source": [
    "# Licensed under a 3-clause BSD style license - see LICENSE.rst\n",
    "\"\"\"Session class driving the high level interface API\"\"\"\n",
    "import logging\n",
    "import yaml\n",
    "import pandas as pd \n",
    "import json\n",
    "\n",
    "from regions import CircleSkyRegion\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "\n",
    "from astropy.units import Quantity\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "\n",
    "# from pydantic import BaseModel\n",
    "from pydantic.utils import deep_update\n",
    "\n",
    "from gammapy.utils.units import energy_unit_format\n",
    "from gammapy.utils.pbar import progress_bar\n",
    "from gammapy.utils.scripts import make_path, read_yaml\n",
    "\n",
    "from gammapy.datasets import (\n",
    "    Datasets,  \n",
    "    MapDataset, \n",
    "    FluxPointsDataset, \n",
    "    SpectrumDatasetOnOff, \n",
    "    SpectrumDataset,\n",
    ")\n",
    "\n",
    "from gammapy.estimators import FluxPoints, SensitivityEstimator\n",
    "from gammapy.maps import Map, MapAxis, RegionGeom, WcsGeom\n",
    "from gammapy.modeling import Fit\n",
    "from gammapy.modeling.models import (\n",
    "    SkyModel, \n",
    "    Models,\n",
    "    Model,\n",
    "    DatasetModels, \n",
    "    FoVBackgroundModel, \n",
    "    Models, \n",
    "    SkyModel, \n",
    "    ExpCutoffPowerLawSpectralModel\n",
    ")\n",
    "\n",
    "from gammapy.data import DataStore\n",
    "from gammapy.estimators import (\n",
    "    ExcessMapEstimator,\n",
    "    FluxPointsEstimator,\n",
    "    LightCurveEstimator,\n",
    ")\n",
    "from gammapy.makers import (\n",
    "    FoVBackgroundMaker,\n",
    "    MapDatasetMaker,\n",
    "    ReflectedRegionsBackgroundMaker,\n",
    "    RingBackgroundMaker,\n",
    "    SafeMaskMaker,\n",
    "    SpectrumDatasetMaker,\n",
    ")\n",
    "\n",
    "from gammapy.data import Observation\n",
    "\n",
    "from gammapy.stats import WStatCountsStatistic\n",
    "\n",
    "from feupy.utils.string_handling import name_to_txt\n",
    "from feupy.utils.datasets import cut_energy_table_fp, write_datasets, read_datasets\n",
    "\n",
    "# from feupy.analysis import CounterpartsAnalysisConfig, SimulationConfig, CTAObservationAnalysisConfig\n",
    "from feupy.cta.irfs import Irfs\n",
    "from feupy.utils.coordinates import skcoord_to_dict, dict_to_skcoord\n",
    "\n",
    "from feupy.analysis.config import CounterpartsConfig, SimulationConfig\n",
    "\n",
    "from feupy.plotters import *\n",
    "\n",
    "from feupy.catalog.config import *\n",
    "\n",
    "from gammapy.data import FixedPointingInfo, PointingMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f9d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4fc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d863eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "__all__ = [\"Counterparts\", \"Simulation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1144f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class Counterparts:\n",
    "    \"\"\"Config-driven high level simulation interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `CounterpartsConfig`\n",
    "        Configuration options following `CounterpartsConfig` schema\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.config.set_logging()\n",
    "#         self.roi = self._create_roi()\n",
    "        \n",
    "#         self._obs = self.config.observations\n",
    "#         self._obs_params = self.config.observations.parameters\n",
    "#         self._obs_target = self.config.observations.target\n",
    "#         self._obs_irfs = self.config.observations.irfs\n",
    "#         self._datasets = self.config.datasets\n",
    "\n",
    "#         self.pointing_position = self._create_pointing_position(\n",
    "#             dict_to_skcoord(self._obs_target.position), \n",
    "#             self._obs_params.offset)\n",
    "#         self.pointing = self._create_pointing(self.pointing_position)\n",
    "\n",
    "#         self._ctao_perf = Irfs\n",
    "#         self._ctao_perf.get_irfs(self._obs_irfs.opt)\n",
    "#         self.observation = self._create_observation(\n",
    "#             dict_to_skcoord(self._obs_target.position), \n",
    "#             self._obs_params.livetime, \n",
    "#             self._ctao_perf.irfs, \n",
    "#             self._ctao_perf.obs_loc\n",
    "#         )\n",
    "        \n",
    "    \n",
    "#         self.datastore = None\n",
    "#         self.observations = None\n",
    "#         self.datasets = None\n",
    "#         self.fit = Fit()\n",
    "#         self.fit_result = None\n",
    "#         self.flux_points = None\n",
    "#         self.dataset_map = None\n",
    "#         self.pointing = dict_to_skcoord(self.config.target.position)\n",
    "#         self._datasets_settings = self.config.datasets\n",
    "#         self._observations_settings = self.config.observations\n",
    "#         self._ctao_perf = Irfs\n",
    "#         self._ctao_perf.get_irfs(self.config.irfs.opt)\n",
    "#         self.observation = None\n",
    "#         self.geom = None\n",
    "#         self.energy_axis_true = self._make_energy_axis(self._datasets_settings.geom.axes.energy_true)\n",
    "#         self.energy_axis_reco = self._make_energy_axis(self._datasets_settings.geom.axes.energy)\n",
    "#         self.spectrum_dataset_empty = None\n",
    "#         self.maker = None\n",
    "#         self.safe_maker = None\n",
    "#         self.spectrum_dataset = None\n",
    "#         self.spectrum_dataset_onoff = None\n",
    "#         self.wstat = None\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _create_region_geometry(center, axes):\n",
    "#         \"\"\"Create the region geometry.\"\"\"\n",
    "#         on_lon = target_position.lon\n",
    "#         on_lat = target_position.lat\n",
    "#         frame = target_position.frame\n",
    "#         pointing = SkyCoord(on_lon, on_lat, frame=frame)\n",
    "#         self._create_pointing_position(\n",
    "#             dict_to_skcoord(self._obs_target.position), \n",
    "#             self._obs_params.offset)\n",
    "        \n",
    "#         on_center = pointing.directional_offset_by(\n",
    "#             position_angle=pointing.dec, \n",
    "#             separation=offset)\n",
    "#         on_region = CircleSkyRegion(on_center, on_region_settings.radius)\n",
    "#         return \n",
    "\n",
    "\n",
    "#     def _create_roi(self):\n",
    "#         \"\"\"Create the geometry.\"\"\"\n",
    "#         log.debug(\"Creating geometry.\")\n",
    "#         target_settings = self.config.target\n",
    "#         config.roi.target.position.lat\n",
    "# config.roi.target.position.lon\n",
    "# config.roi.region_radius\n",
    "# config.roi.region_radius\n",
    "\n",
    "#         obs_settings = self.config.observations\n",
    "#         axes = [self._make_energy_axis(geom_settings.axes.energy)]\n",
    "#         center = dict_to_skcoord(obs_settings.target.position)\n",
    "#         radius = obs_settings.parameters.on_region_radius\n",
    "#         region = self._create_on_region(center, radius)\n",
    "#         return RegionGeom.create(region=region, axes=axes)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def _create_on_region(center, radius):\n",
    "#         \"\"\"Create the region geometry.\n",
    "#         on_region_radius :Angle()\n",
    "#         \"\"\"\n",
    "#         return CircleSkyRegion(\n",
    "#             center=center, \n",
    "#             radius=radius\n",
    "#         )\n",
    "    \n",
    "\n",
    "#     @staticmethod\n",
    "#     def _create_pointing_position(position, separation, position_angle = 0 * u.deg):\n",
    "#         return position.directional_offset_by(position_angle, separation)\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def _create_pointing(pointing_position):\n",
    "#         \"\"\"Create pointing.\"\"\"\n",
    "#         return FixedPointingInfo(\n",
    "#             mode=PointingMode.POINTING,\n",
    "#             fixed_icrs=pointing_position.icrs,\n",
    "#         )\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def _create_observation(pointing, livetime, irfs, location):\n",
    "#         \"\"\"Create an observation.\"\"\"\n",
    "#         return Observation.create(\n",
    "#             pointing=pointing,\n",
    "#             livetime=livetime,\n",
    "#             irfs=irfs,\n",
    "#             location=location,\n",
    "#         )\n",
    "    \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Simulation configuration (`CounterpartsConfig`)\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, dict):\n",
    "            self._config = CounterpartsConfig(**value)\n",
    "        elif isinstance(value, CounterpartsConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be dict or CounterpartsConfig.\")\n",
    "\n",
    "    @property\n",
    "    def models(self):\n",
    "        if not self.datasets:\n",
    "            raise RuntimeError(\"No datasets defined. Impossible to set models.\")\n",
    "        return self.datasets.models\n",
    "\n",
    "    @models.setter\n",
    "    def models(self, models):\n",
    "        self.set_models(models, extend=False)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_energy_axis(config_axis_energy, per_decade=True):\n",
    "        return MapAxis.from_energy_bounds(        \n",
    "            energy_min=config_axis_energy.min, \n",
    "            energy_max=config_axis_energy.max, \n",
    "            nbin=config_axis_energy.nbins, \n",
    "            per_decade=per_decade, \n",
    "            name=config_axis_energy.name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc507f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis = Counterparts(config)\n",
    "# name = analysis.config.roi.target.name\n",
    "# pos_ra = analysis.config.roi.target.position.lon\n",
    "# pos_ra = analysis.config.roi.target.position.lat\n",
    "# model = analysis.config.roi.target.model\n",
    "# Models.from_dict(analysis.config.roi.target.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb20c932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5170122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be61ff61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba3e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class Simulation:\n",
    "    \"\"\"Config-driven high level simulation interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `SimulationConfig`\n",
    "        Configuration options following `SimulationConfig` schema\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.config.set_logging()\n",
    "        self.geom = self._create_geometry()\n",
    "        \n",
    "        self._obs = self.config.observations\n",
    "        self._obs_params = self.config.observations.parameters\n",
    "        self._obs_target = self.config.observations.target\n",
    "        self._obs_irfs = self.config.observations.irfs\n",
    "        self._datasets = self.config.datasets\n",
    "\n",
    "        self.pointing_position = self._create_pointing_position(\n",
    "            dict_to_skcoord(self._obs_target.position), \n",
    "            self._obs_params.offset)\n",
    "        self.pointing = self._create_pointing(self.pointing_position)\n",
    "\n",
    "        self._ctao_perf = Irfs\n",
    "        self._ctao_perf.get_irfs(self._obs_irfs.opt)\n",
    "        self.observation = self._create_observation(\n",
    "            dict_to_skcoord(self._obs_target.position), \n",
    "            self._obs_params.livetime, \n",
    "            self._ctao_perf.irfs, \n",
    "            self._ctao_perf.obs_loc\n",
    "        )\n",
    "        \n",
    "#         self.datastore = None\n",
    "#         self.observations = None\n",
    "#         self.datasets = None\n",
    "#         self.fit = Fit()\n",
    "#         self.fit_result = None\n",
    "#         self.flux_points = None\n",
    "#         self.dataset_map = None\n",
    "#         self.pointing = dict_to_skcoord(self.config.target.position)\n",
    "#         self._datasets_settings = self.config.datasets\n",
    "#         self._observations_settings = self.config.observations\n",
    "#         self._ctao_perf = Irfs\n",
    "#         self._ctao_perf.get_irfs(self.config.irfs.opt)\n",
    "#         self.observation = None\n",
    "#         self.geom = None\n",
    "#         self.energy_axis_true = self._make_energy_axis(self._datasets_settings.geom.axes.energy_true)\n",
    "#         self.energy_axis_reco = self._make_energy_axis(self._datasets_settings.geom.axes.energy)\n",
    "#         self.spectrum_dataset_empty = None\n",
    "#         self.maker = None\n",
    "#         self.safe_maker = None\n",
    "#         self.spectrum_dataset = None\n",
    "#         self.spectrum_dataset_onoff = None\n",
    "#         self.wstat = None\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def _create_region_geometry(center, axes):\n",
    "#         \"\"\"Create the region geometry.\"\"\"\n",
    "#         on_lon = target_position.lon\n",
    "#         on_lat = target_position.lat\n",
    "#         frame = target_position.frame\n",
    "#         pointing = SkyCoord(on_lon, on_lat, frame=frame)\n",
    "#         self._create_pointing_position(\n",
    "#             dict_to_skcoord(self._obs_target.position), \n",
    "#             self._obs_params.offset)\n",
    "        \n",
    "#         on_center = pointing.directional_offset_by(\n",
    "#             position_angle=pointing.dec, \n",
    "#             separation=offset)\n",
    "#         on_region = CircleSkyRegion(on_center, on_region_settings.radius)\n",
    "#         return \n",
    "\n",
    "\n",
    "    def _create_geometry(self):\n",
    "        \"\"\"Create the geometry.\"\"\"\n",
    "        log.debug(\"Creating geometry.\")\n",
    "        geom_settings = self.config.datasets.geom\n",
    "        obs_settings = self.config.observations\n",
    "        axes = [self._make_energy_axis(geom_settings.axes.energy)]\n",
    "        center = dict_to_skcoord(obs_settings.target.position)\n",
    "        radius = obs_settings.parameters.on_region_radius\n",
    "        region = self._create_on_region(center, radius)\n",
    "        return RegionGeom.create(region=region, axes=axes)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_on_region(center, radius):\n",
    "        \"\"\"Create the region geometry.\n",
    "        on_region_radius :Angle()\n",
    "        \"\"\"\n",
    "        return CircleSkyRegion(\n",
    "            center=center, \n",
    "            radius=radius\n",
    "        )\n",
    "    \n",
    "\n",
    "    @staticmethod\n",
    "    def _create_pointing_position(position, separation, position_angle = 0 * u.deg):\n",
    "        return position.directional_offset_by(position_angle, separation)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_pointing(pointing_position):\n",
    "        \"\"\"Create pointing.\"\"\"\n",
    "        return FixedPointingInfo(\n",
    "            mode=PointingMode.POINTING,\n",
    "            fixed_icrs=pointing_position.icrs,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_observation(pointing, livetime, irfs, location):\n",
    "        \"\"\"Create an observation.\"\"\"\n",
    "        return Observation.create(\n",
    "            pointing=pointing,\n",
    "            livetime=livetime,\n",
    "            irfs=irfs,\n",
    "            location=location,\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Simulation configuration (`SimulationConfig`)\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, dict):\n",
    "            self._config = SimulationConfig(**value)\n",
    "        elif isinstance(value, SimulationConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be dict or SimulationConfig.\")\n",
    "\n",
    "    @property\n",
    "    def models(self):\n",
    "        if not self.datasets:\n",
    "            raise RuntimeError(\"No datasets defined. Impossible to set models.\")\n",
    "        return self.datasets.models\n",
    "\n",
    "    @models.setter\n",
    "    def models(self, models):\n",
    "        self.set_models(models, extend=False)\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def _make_energy_axis(config_axis_energy, per_decade=True):\n",
    "        return MapAxis.from_energy_bounds(        \n",
    "            energy_min=config_axis_energy.min, \n",
    "            energy_max=config_axis_energy.max, \n",
    "            nbin=config_axis_energy.nbins, \n",
    "            per_decade=per_decade, \n",
    "            name=config_axis_energy.name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e8e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = Simulation(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c1780",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.config.observations.target.position.lat.deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b196c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.pointing_position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de6d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(analysis.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a437397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.config.observations.target.position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b02cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26997479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71239a39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# __all__ = [\"CounterpartsAnalysis\", \"CTAObservationAnalysis\", 'Simulation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger(__name__)\n",
    "\n",
    "class Simulation_:\n",
    "    \"\"\"Config-driven high level simulation interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `SimulationConfig`\n",
    "        Configuration options following `SimulationConfig` schema\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.config.set_logging()\n",
    "        self.datastore = None\n",
    "        self.observations = None\n",
    "        self.datasets = None\n",
    "        self.fit = Fit()\n",
    "        self.fit_result = None\n",
    "        self.flux_points = None\n",
    "        self.dataset_map = None\n",
    "        self.pointing = dict_to_skcoord(self.config.target.position)\n",
    "        self._datasets_settings = self.config.datasets\n",
    "        self._observations_settings = self.config.observations\n",
    "        self._ctao_perf = Irfs\n",
    "        self._ctao_perf.get_irfs(self.config.irfs.opt)\n",
    "        self.observation = None\n",
    "        self.geom = None\n",
    "        self.energy_axis_true = self._make_energy_axis(self._datasets_settings.geom.axes.energy_true)\n",
    "        self.energy_axis_reco = self._make_energy_axis(self._datasets_settings.geom.axes.energy)\n",
    "        self.spectrum_dataset_empty = None\n",
    "        self.maker = None\n",
    "        self.safe_maker = None\n",
    "        self.spectrum_dataset = None\n",
    "        self.spectrum_dataset_onoff = None\n",
    "        self.wstat = None\n",
    "        \n",
    "\n",
    "        \n",
    "    @property\n",
    "    def models(self):\n",
    "        if not self.datasets:\n",
    "            raise RuntimeError(\"No datasets defined. Impossible to set models.\")\n",
    "        return self.datasets.models\n",
    "\n",
    "    @models.setter\n",
    "    def models(self, models):\n",
    "        self.set_models(models, extend=False)\n",
    "\n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Simulation configuration (`SimulationConfig`)\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, dict):\n",
    "            self._config = SimulationConfig(**value)\n",
    "        elif isinstance(value, SimulationConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be dict or SimulationConfig.\")\n",
    "\n",
    "    def _set_data_store(self):\n",
    "        \"\"\"Set the datastore on the Simulation object.\"\"\"\n",
    "        path = make_path(self.config.observations.datastore)\n",
    "        if path.is_file():\n",
    "            log.debug(f\"Setting datastore from file: {path}\")\n",
    "            self.datastore = DataStore.from_file(path)\n",
    "        elif path.is_dir():\n",
    "            log.debug(f\"Setting datastore from directory: {path}\")\n",
    "            self.datastore = DataStore.from_dir(path)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Datastore not found: {path}\")\n",
    "\n",
    "    def _make_obs_table_selection(self):\n",
    "        \"\"\"Return list of obs_ids after filtering on datastore observation table.\"\"\"\n",
    "        obs_settings = self.config.observations\n",
    "\n",
    "        # Reject configs with list of obs_ids and obs_file set at the same time\n",
    "        if len(obs_settings.obs_ids) and obs_settings.obs_file is not None:\n",
    "            raise ValueError(\n",
    "                \"Values for both parameters obs_ids and obs_file are not accepted.\"\n",
    "            )\n",
    "\n",
    "        # First select input list of observations from obs_table\n",
    "        if len(obs_settings.obs_ids):\n",
    "            selected_obs_table = self.datastore.obs_table.select_obs_id(\n",
    "                obs_settings.obs_ids\n",
    "            )\n",
    "        elif obs_settings.obs_file is not None:\n",
    "            path = make_path(obs_settings.obs_file)\n",
    "            ids = list(Table.read(path, format=\"ascii\", data_start=0).columns[0])\n",
    "            selected_obs_table = self.datastore.obs_table.select_obs_id(ids)\n",
    "        else:\n",
    "            selected_obs_table = self.datastore.obs_table\n",
    "\n",
    "        # Apply cone selection\n",
    "        if obs_settings.obs_cone.lon is not None:\n",
    "            cone = dict(\n",
    "                type=\"sky_circle\",\n",
    "                frame=obs_settings.obs_cone.frame,\n",
    "                lon=obs_settings.obs_cone.lon,\n",
    "                lat=obs_settings.obs_cone.lat,\n",
    "                radius=obs_settings.obs_cone.radius,\n",
    "                border=\"0 deg\",\n",
    "            )\n",
    "            selected_obs_table = selected_obs_table.select_observations(cone)\n",
    "\n",
    "        return selected_obs_table[\"OBS_ID\"].tolist()\n",
    "\n",
    "    def get_observations(self):\n",
    "        \"\"\"Fetch observations from the data store according to criteria defined\n",
    "        in the configuration.\"\"\"\n",
    "        observations_settings = self.config.observations\n",
    "        self._set_data_store()\n",
    "\n",
    "        log.info(\"Fetching observations.\")\n",
    "        ids = self._make_obs_table_selection()\n",
    "        required_irf = [_.value for _ in observations_settings.required_irf]\n",
    "        self.observations = self.datastore.get_observations(\n",
    "            ids, skip_missing=True, required_irf=required_irf\n",
    "        )\n",
    "\n",
    "        if observations_settings.obs_time.start is not None:\n",
    "            start = observations_settings.obs_time.start\n",
    "            stop = observations_settings.obs_time.stop\n",
    "            if len(start.shape) == 0:\n",
    "                time_intervals = [(start, stop)]\n",
    "            else:\n",
    "                time_intervals = [(tstart, tstop) for tstart, tstop in zip(start, stop)]\n",
    "            self.observations = self.observations.select_time(time_intervals)\n",
    "\n",
    "        log.info(f\"Number of selected observations: {len(self.observations)}\")\n",
    "\n",
    "        for obs in self.observations:\n",
    "            log.debug(obs)\n",
    "\n",
    "    def get_datasets(self):\n",
    "        dataset_onoff = self._making_spectrum_dataset_onoff()\n",
    "        dataset = self.spectrum_dataset\n",
    "        \n",
    "        datasets = Datasets()\n",
    "\n",
    "        for idx in range(self.config.observations.parameters.n_obs):\n",
    "            dataset_onoff.fake(\n",
    "                random_state=idx, \n",
    "                npred_background=dataset.npred_background()\n",
    "            )\n",
    "            dataset_fake = dataset_onoff.copy(name=f\"obs-{idx}\")\n",
    "            dataset_fake.meta_table[\"OBS_ID\"] = [idx]\n",
    "            datasets.append(dataset_fake)\n",
    "    \n",
    "            self.datasets = datasets\n",
    "    \n",
    "    def _making_spectrum_dataset_onoff(self):\n",
    "        \"\"\"Produce reduced datasets.\"\"\"\n",
    "        datasets_settings = self.config.datasets\n",
    "        observations_settings = self.config.observations\n",
    "        target_settings = self.config.target\n",
    "        ctao_perf = self._ctao_perf\n",
    "        \n",
    "        observation = self._create_observation(\n",
    "            dict_to_skcoord(target_settings.position), \n",
    "            observations_settings.parameters.livetime, \n",
    "            ctao_perf.irfs, \n",
    "            ctao_perf.obs_loc\n",
    "        )\n",
    "        \n",
    "        geom = self._create_geometry()\n",
    "        \n",
    "        dataset_empty = self._create_spectrum_dataset_empty(\n",
    "            geom,\n",
    "            self._make_energy_axis(datasets_settings.geom.axes.energy_true)\n",
    "        )\n",
    "        \n",
    "        maker = self._create_dataset_maker()\n",
    "        safe_maker = self._create_safe_mask_maker()\n",
    "        dataset = maker.run(dataset_empty, observation) \n",
    "        dataset = safe_maker.run(dataset, observation)\n",
    "        \n",
    "        log.info(\"Set the model on the dataset, and fake.\")\n",
    "        \n",
    "        model_dict = target_settings.model\n",
    "        sky_model = Model.from_dict(model_dict)\n",
    "        dataset.models = sky_model\n",
    "        dataset.fake(random_state=42)\n",
    "        self.geom = geom\n",
    "        self.observation = observation\n",
    "        self.spectrum_dataset_empty = dataset_empty\n",
    "        self.maker = maker\n",
    "        self.safe_maker = safe_maker\n",
    "        self.spectrum_dataset = dataset\n",
    "        \n",
    "        dataset_onoff = self._create_spectrum_dataset_onoff(\n",
    "            dataset, \n",
    "            datasets_settings.acceptance, \n",
    "            datasets_settings.acceptance_off)\n",
    "        \n",
    "        self.spectrum_dataset_onoff = dataset_onoff\n",
    "        \n",
    "        return dataset_onoff\n",
    "    \n",
    "    def set_models(self, models, extend=True):\n",
    "        \"\"\"Set models on datasets.\n",
    "        Adds `FoVBackgroundModel` if not present already\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        models : `~gammapy.modeling.models.Models` or str\n",
    "            Models object or YAML models string\n",
    "        extend : bool\n",
    "            Extend the exiting models on the datasets or replace them.\n",
    "        \"\"\"\n",
    "        if not self.datasets or len(self.datasets) == 0:\n",
    "            raise RuntimeError(\"Missing datasets\")\n",
    "\n",
    "        log.info(\"Reading model.\")\n",
    "        if isinstance(models, str):\n",
    "            models = Models.from_yaml(models)\n",
    "        elif isinstance(models, Models):\n",
    "            pass\n",
    "        elif isinstance(models, DatasetModels) or isinstance(models, list):\n",
    "            models = Models(models)\n",
    "        else:\n",
    "            raise TypeError(f\"Invalid type: {models!r}\")\n",
    "\n",
    "        if extend:\n",
    "            models.extend(self.datasets.models)\n",
    "\n",
    "        self.datasets.models = models\n",
    "\n",
    "        bkg_models = []\n",
    "        for dataset in self.datasets:\n",
    "            if dataset.tag == \"MapDataset\" and dataset.background_model is None:\n",
    "                bkg_models.append(FoVBackgroundModel(dataset_name=dataset.name))\n",
    "        if bkg_models:\n",
    "            models.extend(bkg_models)\n",
    "            self.datasets.models = models\n",
    "\n",
    "        log.info(models)\n",
    "\n",
    "    def read_models(self, path, extend=True):\n",
    "        \"\"\"Read models from YAML file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        path : str\n",
    "            path to the model file\n",
    "        extend : bool\n",
    "            Extend the exiting models on the datasets or replace them.\n",
    "        \"\"\"\n",
    "\n",
    "        path = make_path(path)\n",
    "        models = Models.read(path)\n",
    "        self.set_models(models, extend=extend)\n",
    "        log.info(f\"Models loaded from {path}.\")\n",
    "\n",
    "    def write_models(self, overwrite=True, write_covariance=True):\n",
    "        \"\"\"Write models to YAML file.\n",
    "        File name is taken from the configuration file.\n",
    "        \"\"\"\n",
    "\n",
    "        filename_models = self.config.general.models_file\n",
    "        if filename_models is not None:\n",
    "            self.models.write(\n",
    "                filename_models, overwrite=overwrite, write_covariance=write_covariance\n",
    "            )\n",
    "            log.info(f\"Models loaded from {filename_models}.\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Missing models_file in config.general\")\n",
    "\n",
    "    def read_datasets(self):\n",
    "        \"\"\"Read datasets from YAML file.\n",
    "        File names are taken from the configuration file.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        filename = self.config.general.datasets_file\n",
    "        filename_models = self.config.general.models_file\n",
    "        if filename is not None:\n",
    "            self.datasets = Datasets.read(filename)\n",
    "            log.info(f\"Datasets loaded from {filename}.\")\n",
    "            if filename_models is not None:\n",
    "                self.read_models(filename_models, extend=False)\n",
    "        else:\n",
    "            raise RuntimeError(\"Missing datasets_file in config.general\")\n",
    "\n",
    "    def write_datasets(self, overwrite=True, write_covariance=True):\n",
    "        \"\"\"Write datasets to YAML file.\n",
    "        File names are taken from the configuration file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        overwrite : bool\n",
    "            overwrite datasets FITS files\n",
    "        write_covariance : bool\n",
    "            save covariance or not\n",
    "        \"\"\"\n",
    "\n",
    "        filename = self.config.general.datasets_file\n",
    "        filename_models = self.config.general.models_file\n",
    "        if filename is not None:\n",
    "            self.datasets.write(\n",
    "                filename,\n",
    "                filename_models,\n",
    "                overwrite=overwrite,\n",
    "                write_covariance=write_covariance,\n",
    "            )\n",
    "            log.info(f\"Datasets stored to {filename}.\")\n",
    "            log.info(f\"Datasets stored to {filename_models}.\")\n",
    "        else:\n",
    "            raise RuntimeError(\"Missing datasets_file in config.general\")\n",
    "\n",
    "    def run_fit(self):\n",
    "        \"\"\"Fitting reduced datasets to model.\"\"\"\n",
    "        if not self.models:\n",
    "            raise RuntimeError(\"Missing models\")\n",
    "\n",
    "        fit_settings = self.config.fit\n",
    "        for dataset in self.datasets:\n",
    "            if fit_settings.fit_range:\n",
    "                energy_min = fit_settings.fit_range.min\n",
    "                energy_max = fit_settings.fit_range.max\n",
    "                geom = dataset.counts.geom\n",
    "                dataset.mask_fit = geom.energy_mask(energy_min, energy_max)\n",
    "\n",
    "        log.info(\"Fitting datasets.\")\n",
    "        result = self.fit.run(datasets=self.datasets)\n",
    "        self.fit_result = result\n",
    "        log.info(self.fit_result)\n",
    "\n",
    "    def get_flux_points(self):\n",
    "        \"\"\"Calculate flux points for a specific model component.\"\"\"\n",
    "        if not self.datasets:\n",
    "            raise RuntimeError(\n",
    "                \"No datasets defined. Impossible to compute flux points.\"\n",
    "            )\n",
    "\n",
    "        fp_settings = self.config.flux_points\n",
    "        log.info(\"Calculating flux points.\")\n",
    "        energy_edges = self._make_energy_axis(fp_settings.energy).edges\n",
    "        flux_point_estimator = FluxPointsEstimator(\n",
    "            energy_edges=energy_edges,\n",
    "            source=fp_settings.source,\n",
    "            fit=self.fit,\n",
    "            n_jobs=self.config.general.n_jobs,\n",
    "            **fp_settings.parameters,\n",
    "        )\n",
    "\n",
    "        fp = flux_point_estimator.run(datasets=self.datasets)\n",
    "\n",
    "        self.flux_points = FluxPointsDataset(\n",
    "            data=fp, models=self.models[fp_settings.source]\n",
    "        )\n",
    "        cols = [\"e_ref\", \"dnde\", \"dnde_ul\", \"dnde_err\", \"sqrt_ts\"]\n",
    "        table = self.flux_points.data.to_table(sed_type=\"dnde\")\n",
    "        log.info(\"\\n{}\".format(table[cols]))\n",
    "\n",
    "    def get_excess_map(self):\n",
    "        \"\"\"Calculate excess map with respect to the current model.\"\"\"\n",
    "        excess_settings = self.config.excess_map\n",
    "        log.info(\"Computing excess maps.\")\n",
    "\n",
    "        # TODO: Here we could possibly stack the datasets if needed\n",
    "        # or allow to compute the excess map for each dataset\n",
    "        if len(self.datasets) > 1:\n",
    "            raise ValueError(\"Datasets must be stacked to compute the excess map\")\n",
    "\n",
    "        if self.datasets[0].tag not in [\"MapDataset\", \"MapDatasetOnOff\"]:\n",
    "            raise ValueError(\"Cannot compute excess map for 1D dataset\")\n",
    "\n",
    "        energy_edges = self._make_energy_axis(excess_settings.energy_edges)\n",
    "        if energy_edges is not None:\n",
    "            energy_edges = energy_edges.edges\n",
    "\n",
    "        excess_map_estimator = ExcessMapEstimator(\n",
    "            correlation_radius=excess_settings.correlation_radius,\n",
    "            energy_edges=energy_edges,\n",
    "            **excess_settings.parameters,\n",
    "        )\n",
    "        self.excess_map = excess_map_estimator.run(self.datasets[0])\n",
    "\n",
    "    def get_light_curve(self):\n",
    "        \"\"\"Calculate light curve for a specific model component.\"\"\"\n",
    "        lc_settings = self.config.light_curve\n",
    "        log.info(\"Computing light curve.\")\n",
    "        energy_edges = self._make_energy_axis(lc_settings.energy_edges).edges\n",
    "\n",
    "        if (\n",
    "            lc_settings.time_intervals.start is None\n",
    "            or lc_settings.time_intervals.stop is None\n",
    "        ):\n",
    "            log.info(\n",
    "                \"Time intervals not defined. Extract light curve on datasets GTIs.\"\n",
    "            )\n",
    "            time_intervals = None\n",
    "        else:\n",
    "            time_intervals = [\n",
    "                (t1, t2)\n",
    "                for t1, t2 in zip(\n",
    "                    lc_settings.time_intervals.start, lc_settings.time_intervals.stop\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        light_curve_estimator = LightCurveEstimator(\n",
    "            time_intervals=time_intervals,\n",
    "            energy_edges=energy_edges,\n",
    "            source=lc_settings.source,\n",
    "            fit=self.fit,\n",
    "            n_jobs=self.config.general.n_jobs,\n",
    "            **lc_settings.parameters,\n",
    "        )\n",
    "        lc = light_curve_estimator.run(datasets=self.datasets)\n",
    "        self.light_curve = lc\n",
    "        log.info(\n",
    "            \"\\n{}\".format(\n",
    "                self.light_curve.to_table(format=\"lightcurve\", sed_type=\"flux\")\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def update_config(self, config):\n",
    "        self.config = self.config.update(config=config)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_wcs_geometry(wcs_geom_settings, axes):\n",
    "        \"\"\"Create the WCS geometry.\"\"\"\n",
    "        geom_params = {}\n",
    "        skydir_settings = wcs_geom_settings.skydir\n",
    "        if skydir_settings.lon is not None:\n",
    "            skydir = SkyCoord(\n",
    "                skydir_settings.lon, skydir_settings.lat, frame=skydir_settings.frame\n",
    "            )\n",
    "            geom_params[\"skydir\"] = skydir\n",
    "\n",
    "        if skydir_settings.frame in [\"icrs\", \"galactic\"]:\n",
    "            geom_params[\"frame\"] = skydir_settings.frame\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Incorrect skydir frame: expect 'icrs' or 'galactic'. Got {skydir_settings.frame}\"\n",
    "            )\n",
    "\n",
    "        geom_params[\"axes\"] = axes\n",
    "        geom_params[\"binsz\"] = wcs_geom_settings.binsize\n",
    "        width = wcs_geom_settings.width.width.to(\"deg\").value\n",
    "        height = wcs_geom_settings.width.height.to(\"deg\").value\n",
    "        geom_params[\"width\"] = (width, height)\n",
    "\n",
    "        return WcsGeom.create(**geom_params)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_region_geometry(on_region_settings, axes, offset):\n",
    "        \"\"\"Create the region geometry.\"\"\"\n",
    "        on_lon = on_region_settings.lon\n",
    "        on_lat = on_region_settings.lat\n",
    "        pointing = SkyCoord(on_lon, on_lat, frame=on_region_settings.frame)\n",
    "        on_center = pointing.directional_offset_by(\n",
    "            position_angle=pointing.dec, \n",
    "            separation=offset)\n",
    "        on_region = CircleSkyRegion(on_center, on_region_settings.radius)\n",
    "        return RegionGeom.create(region=on_region, axes=axes)\n",
    "\n",
    "\n",
    "    def _create_geometry(self):\n",
    "        \"\"\"Create the geometry.\"\"\"\n",
    "        log.debug(\"Creating geometry.\")\n",
    "        datasets_settings = self.config.datasets\n",
    "        geom_settings = datasets_settings.geom\n",
    "        observations_settings = self.config.observations\n",
    "        offset = observations_settings.parameters.offset\n",
    "        axes = [self._make_energy_axis(geom_settings.axes.energy)]\n",
    "        if datasets_settings.type == \"3d\":\n",
    "            geom = self._create_wcs_geometry(geom_settings.wcs, axes)\n",
    "        elif datasets_settings.type == \"1d\":\n",
    "            geom = self._create_region_geometry(\n",
    "                datasets_settings.on_region, axes, offset)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Incorrect dataset type. Expect '1d' or '3d'. Got {datasets_settings.type}.\"\n",
    "            )\n",
    "        return geom\n",
    "\n",
    "    def _create_reference_dataset(self, name=None):\n",
    "        \"\"\"Create the reference dataset for the current analysis.\"\"\"\n",
    "        log.debug(\"Creating target Dataset.\")\n",
    "        geom = self._create_geometry()\n",
    "\n",
    "        geom_settings = self.config.datasets.geom\n",
    "        geom_irf = dict(energy_axis_true=None, binsz_irf=None)\n",
    "        if geom_settings.axes.energy_true.min is not None:\n",
    "            geom_irf[\"energy_axis_true\"] = self._make_energy_axis(\n",
    "                geom_settings.axes.energy_true, name=\"energy_true\"\n",
    "            )\n",
    "        if geom_settings.wcs.binsize_irf is not None:\n",
    "            geom_irf[\"binsz_irf\"] = geom_settings.wcs.binsize_irf.to(\"deg\").value\n",
    "\n",
    "        if self.config.datasets.type == \"1d\":\n",
    "            return SpectrumDataset.create(geom, name=name, **geom_irf)\n",
    "        else:\n",
    "            return MapDataset.create(geom, name=name, **geom_irf)\n",
    "\n",
    "    def _create_dataset_maker(self):\n",
    "        \"\"\"Create the Dataset Maker.\"\"\"\n",
    "        log.debug(\"Creating the target Dataset Maker.\")\n",
    "\n",
    "        datasets_settings = self.config.datasets\n",
    "        if datasets_settings.type == \"3d\":\n",
    "            maker = MapDatasetMaker(selection=datasets_settings.selection)\n",
    "        elif datasets_settings.type == \"1d\":\n",
    "            maker_config = {}\n",
    "            if datasets_settings.containment_correction:\n",
    "                maker_config[\n",
    "                    \"containment_correction\"\n",
    "                ] = datasets_settings.containment_correction\n",
    "\n",
    "            maker_config[\"selection\"] = datasets_settings.selection\n",
    "            maker_config[\"use_region_center\"] = datasets_settings.use_region_center\n",
    "            maker = SpectrumDatasetMaker(**maker_config)\n",
    "\n",
    "        return maker\n",
    "\n",
    "    def _create_safe_mask_maker(self):\n",
    "        \"\"\"Create the SafeMaskMaker.\"\"\"\n",
    "        log.debug(\"Creating the mask_safe Maker.\")\n",
    "\n",
    "        safe_mask_selection = self.config.datasets.safe_mask.methods\n",
    "        safe_mask_settings = self.config.datasets.safe_mask.parameters\n",
    "        return SafeMaskMaker(methods=safe_mask_selection, **safe_mask_settings)\n",
    "\n",
    "    def _create_background_maker(self):\n",
    "        \"\"\"Create the Background maker.\"\"\"\n",
    "        log.info(\"Creating the background Maker.\")\n",
    "\n",
    "        datasets_settings = self.config.datasets\n",
    "        bkg_maker_config = {}\n",
    "        if datasets_settings.background.exclusion:\n",
    "            path = make_path(datasets_settings.background.exclusion)\n",
    "            exclusion_mask = Map.read(path)\n",
    "            exclusion_mask.data = exclusion_mask.data.astype(bool)\n",
    "            bkg_maker_config[\"exclusion_mask\"] = exclusion_mask\n",
    "        bkg_maker_config.update(datasets_settings.background.parameters)\n",
    "\n",
    "        bkg_method = datasets_settings.background.method\n",
    "\n",
    "        bkg_maker = None\n",
    "        if bkg_method == \"fov_background\":\n",
    "            log.debug(f\"Creating FoVBackgroundMaker with arguments {bkg_maker_config}\")\n",
    "            bkg_maker = FoVBackgroundMaker(**bkg_maker_config)\n",
    "        elif bkg_method == \"ring\":\n",
    "            bkg_maker = RingBackgroundMaker(**bkg_maker_config)\n",
    "            log.debug(f\"Creating RingBackgroundMaker with arguments {bkg_maker_config}\")\n",
    "            if datasets_settings.geom.axes.energy.nbins > 1:\n",
    "                raise ValueError(\n",
    "                    \"You need to define a single-bin energy geometry for your dataset.\"\n",
    "                )\n",
    "        elif bkg_method == \"reflected\":\n",
    "            bkg_maker = ReflectedRegionsBackgroundMaker(**bkg_maker_config)\n",
    "            log.debug(\n",
    "                f\"Creating ReflectedRegionsBackgroundMaker with arguments {bkg_maker_config}\"\n",
    "            )\n",
    "        else:\n",
    "            log.warning(\"No background maker set. Check configuration.\")\n",
    "        return bkg_maker\n",
    "\n",
    "    def compute_wstat(self):\n",
    "        # Class to compute statistics for Poisson distributed variable with unknown background.\n",
    "        \n",
    "        self.wstat = WStatCountsStatistic(\n",
    "            n_on=sum(self.spectrum_dataset_onoff.counts.data), \n",
    "            n_off=sum(self.spectrum_dataset_onoff.counts_off.data), \n",
    "            alpha=self.config.datasets.alpha)\n",
    "\n",
    "    def map_making(self):\n",
    "        \"\"\"Make maps and datasets for 3d analysis\"\"\"\n",
    "        datasets_settings = self.config.datasets\n",
    "        observations_settings = self.config.observations\n",
    "        target_settings = self.config.target\n",
    "        ctao_perf = self._ctao_perf\n",
    "        pointing = dict_to_skcoord(target_settings.position)\n",
    "        observation = self._create_observation(\n",
    "            pointing, \n",
    "            observations_settings.parameters.livetime, \n",
    "            ctao_perf.irfs, \n",
    "            ctao_perf.obs_loc\n",
    "        )\n",
    "        log.info(\"Creating reference dataset and makers.\")\n",
    "\n",
    "        dataset_empty = self._create_spectrum_dataset_empty(\n",
    "            self._create_geometry(), \n",
    "            self._make_energy_axis(datasets_settings.geom.axes.energy_true)\n",
    "        )\n",
    "\n",
    "        maker = self._create_dataset_maker()\n",
    "        safe_maker = self._create_safe_mask_maker()\n",
    "        dataset = maker.run(dataset_empty, observation)\n",
    "        dataset = safe_maker.run(dataset, observation)\n",
    "\n",
    "        log.info(\"Set the model on the dataset, and fake.\")\n",
    "\n",
    "        dataset.models = Model.from_dict(target_settings.model)\n",
    "        dataset.fake(random_state=42)\n",
    "        self.dataset_map = dataset\n",
    "\n",
    "    def _spectrum_extraction(self):\n",
    "        \"\"\"Run all steps for the spectrum extraction.\"\"\"\n",
    "        log.info(\"Reducing spectrum datasets.\")\n",
    "        datasets_settings = self.config.datasets\n",
    "        dataset_maker = self._create_dataset_maker()\n",
    "        safe_mask_maker = self._create_safe_mask_maker()\n",
    "        bkg_maker = self._create_background_maker()\n",
    "\n",
    "        reference = self._create_reference_dataset()\n",
    "\n",
    "        datasets = []\n",
    "        for obs in progress_bar(self.observations, desc=\"Observations\"):\n",
    "            log.debug(f\"Processing observation {obs.obs_id}\")\n",
    "            dataset = dataset_maker.run(reference.copy(), obs)\n",
    "            if bkg_maker is not None:\n",
    "                dataset = bkg_maker.run(dataset, obs)\n",
    "                if dataset.counts_off is None:\n",
    "                    log.debug(\n",
    "                        f\"No OFF region found for observation {obs.obs_id}. Discarding.\"\n",
    "                    )\n",
    "                    continue\n",
    "            dataset = safe_mask_maker.run(dataset, obs)\n",
    "            log.debug(dataset)\n",
    "            datasets.append(dataset)\n",
    "        self.datasets = Datasets(datasets)\n",
    "\n",
    "        if datasets_settings.stack:\n",
    "            stacked = self.datasets.stack_reduce(name=\"stacked\")\n",
    "            self.datasets = Datasets([stacked])\n",
    "            \n",
    "            \n",
    "    @staticmethod    \n",
    "    def _create_spectrum_dataset_onoff(dataset, acceptance, acceptance_off):\n",
    "    # Spectrum dataset for on-off likelihood fitting.\n",
    "        dataset_onoff = SpectrumDatasetOnOff.from_spectrum_dataset(\n",
    "            dataset=dataset, \n",
    "            acceptance=acceptance, \n",
    "            acceptance_off=acceptance_off,\n",
    "        )\n",
    "        dataset_onoff.fake(\n",
    "            random_state='random-seed', \n",
    "            npred_background=dataset.npred_background()\n",
    "        )\n",
    "        return(dataset_onoff)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_on_region(center, radius):\n",
    "        \"\"\"Create the region geometry.\n",
    "        on_region_radius :Angle()\n",
    "        \"\"\"\n",
    "        return CircleSkyRegion(\n",
    "            center=center, \n",
    "            radius=radius\n",
    "        )\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_observation(pointing, livetime, irfs, location):\n",
    "        \"\"\"Create an observation.\"\"\"\n",
    "        return Observation.create(\n",
    "            pointing=pointing,\n",
    "            livetime=livetime,\n",
    "            irfs=irfs,\n",
    "            location=location,\n",
    "        )\n",
    "\n",
    "    def estimate_sensitivity(self):\n",
    "        sensitivity_settings = self.config.sensitivity\n",
    "        sensitivity = SensitivityEstimator(\n",
    "            spectrum=Model.from_dict(self.config.target.model).spectral_model,\n",
    "            gamma_min=sensitivity_settings.gamma_min, \n",
    "            n_sigma=sensitivity_settings.n_sigma, \n",
    "            bkg_syst_fraction=sensitivity_settings.bkg_syst_fraction\n",
    "        )\n",
    "        self.sens = sensitivity\n",
    "        self.sensitivity_table = sensitivity.run(self.spectrum_dataset_onoff)\n",
    "        \n",
    "\n",
    "    @staticmethod\n",
    "    def _create_spectrum_dataset_empty(geom, energy_axis_true, name=\"obs-0\"):\n",
    "        \"\"\"Create a MapDataset object with zero filled maps.\"\"\"\n",
    "        return SpectrumDataset.create(\n",
    "            geom=geom, \n",
    "            energy_axis_true=energy_axis_true,\n",
    "            name=name,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_center(pointing, offset):\n",
    "        return pointing.directional_offset_by(position_angle=pointing.dec, separation=offset)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_energy_axis(config_axis_energy, per_decade=True):\n",
    "        return MapAxis.from_energy_bounds(        \n",
    "            energy_min=config_axis_energy.min, \n",
    "            energy_max=config_axis_energy.max, \n",
    "            nbin=config_axis_energy.nbins, \n",
    "            per_decade=per_decade, \n",
    "            name=config_axis_energy.name,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e13019",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimulationConfig.read(\"config.yaml\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2f868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f04ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io.fits.verify import VerifyWarning\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CounterpartsAnalysis:\n",
    "    \"\"\"Config-driven high level analysis interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `~gammapy.analysis.counterparts.CounterpartsAnalysisConfig`\n",
    "        Configuration options following `CounterpartsAnalysisConfig` schema.\n",
    "    \"\"\"\n",
    "    all = []\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.catalogs = None\n",
    "        self.datasets = None\n",
    "#         self.sources = self.config.roi.sources\n",
    "        self.sources = None\n",
    "        self.models = None\n",
    "        self.pulsars = None\n",
    "        self.dict_roi = None\n",
    "        self.df_roi = None\n",
    "        CounterpartsAnalysis.all.append(self)\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Analysis configuration as an `~feupy.analysis.CounterpartsAnalysisConfig` object.\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, CounterpartsAnalysisConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be CounterpartsAnalysisConfig\")\n",
    "            \n",
    "    def run(self):\n",
    "        self._get_datasets()\n",
    "        self._get_dict_roi()\n",
    "        self._get_df_roi()\n",
    "        \n",
    "    def _get_datasets(self):\n",
    "        \"\"\"\n",
    "        Select a catalog subset (only sources within a region of interest)\n",
    "        \"\"\"\n",
    "        _catalogs = self.config.roi.catalogs\n",
    "        self.pulsars = self.config.roi.pulsars\n",
    "\n",
    "        datasets = Datasets() # global datasets object\n",
    "        models = Models()  # global models object\n",
    "        sources = [] # global sources object\n",
    "        catalogs = []\n",
    "        n_sources = 0 # number of sources\n",
    "        n_flux_points = 0 # number of flux points tables\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore', VerifyWarning)\n",
    "            for catalog in _catalogs:\n",
    "                indexes = []\n",
    "                cat_tag = catalog.tag\n",
    "                for source in catalog:\n",
    "                    n_sources += 1   \n",
    "                    source_name = source.name \n",
    "                    index = source.row_index\n",
    "                    if cat_tag == PULSARTAG:\n",
    "                        pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            flux_points = source.flux_points\n",
    "\n",
    "                            spectral_model = source.spectral_model()\n",
    "                            spectral_model_tag = spectral_model.tag[1]\n",
    "\n",
    "                            if cat_tag == 'gamma-cat' or cat_tag == 'hgps':\n",
    "                                dataset_name = f'{source_name}: {cat_tag}'\n",
    "                            else: dataset_name = source_name\n",
    "\n",
    "                            file_name = name_to_txt(dataset_name)\n",
    "\n",
    "                            model = SkyModel(\n",
    "                                name=f\"{file_name}_{spectral_model_tag}\",\n",
    "                                spectral_model=spectral_model,\n",
    "                                datasets_names=dataset_name\n",
    "                            )\n",
    "\n",
    "                            dataset = FluxPointsDataset(\n",
    "                                models=model,\n",
    "                                data=flux_points, \n",
    "                                name=dataset_name   \n",
    "                            )\n",
    "\n",
    "                            if any([self.config.e_ref_min !=  None, self.config.e_ref_max !=  None]):\n",
    "                                dataset = cut_energy_table_fp(dataset, self.config.e_ref_min, self.config.e_ref_max) \n",
    "\n",
    "                            n_flux_points += 1\n",
    "                            models.append(model)  # Add the model to models()\n",
    "                            datasets.append(dataset)\n",
    "                            sources.append(source)\n",
    "                        except Exception as error:\n",
    "                            indexes.append(index)\n",
    "                            # By this way we can know about the type of error occurring\n",
    "                            print(f'The error is: ({source_name}) {error}') \n",
    "                if len(indexes)>0:\n",
    "                    if len(indexes)==1:\n",
    "                        catalog.table.remove_row(indexes[0])\n",
    "                    else: catalog.table.remove_rows(indexes)\n",
    "\n",
    "                if len(catalog.table)>0:\n",
    "                    catalogs.append(catalog)\n",
    "            datasets.models = models\n",
    "            self.datasets = datasets\n",
    "            self.models = models\n",
    "            self.sources = sources\n",
    "            self.catalogs = catalogs\n",
    "\n",
    "            print(f\"Total number of gamma sources: {len(self.sources)}\")\n",
    "            print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "            print(f\"Total number of pulsars: {len(self.pulsars)}\")\n",
    "\n",
    "#     def sensitivity_estimator(self):\n",
    "\n",
    "             \n",
    "    def _get_dict_roi(self):\n",
    "        _dict_roi = {}\n",
    "\n",
    "        roi_pos = self.config.roi.target.position \n",
    "        radius_roi = self.config.roi.radius \n",
    "\n",
    "        _sources = self.sources.copy()\n",
    "        _sources.extend(self.pulsars)\n",
    "        for index, source in enumerate(_sources):\n",
    "            source_pos = source.position\n",
    "            sep = source.position.separation(roi_pos).deg\n",
    "            if index < len(self.datasets):\n",
    "                name = self.datasets[index].name\n",
    "            else: name = source.name\n",
    "            _dict_roi[name] = {\n",
    "                'position': source_pos,\n",
    "                'separation':sep\n",
    "            }\n",
    "\n",
    "        self.dict_roi = _dict_roi\n",
    "        \n",
    "    def _get_df_roi(self):\n",
    "        _dict = self.dict_roi\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Source name\"] = _dict.keys()\n",
    "        df_ra = []\n",
    "        df_dec = []\n",
    "        df_sep = []\n",
    "\n",
    "        for index, name in enumerate(_dict.keys()):\n",
    "            df_ra.append(_dict[name][\"position\"].ra.deg)\n",
    "            df_dec.append(_dict[name][\"position\"].dec.deg)\n",
    "            df_sep.append(_dict[name][\"separation\"])\n",
    "\n",
    "        df[\"RA(deg)\"] = df_ra\n",
    "        df[\"dec.(deg)\"] = df_dec\n",
    "        df[\"Sep.(deg)\"] = df_sep\n",
    "        self.df_roi = df\n",
    "        \n",
    "    def create_analysis_name(self): \n",
    "        \"\"\" ... \"\"\"\n",
    "        ss = f\"{self.config.target.name}\"\n",
    "        ss += \"_roi_{:.2f}\".format(self.config.roi.radius).replace(' ', '')\n",
    "        if self.config.e_ref_min is None: ss += \"\"\n",
    "        else: ss += \"_e_ref_min_{}\".format(energy_unit_format(self.config.e_ref_min).replace(' ', ''))\n",
    "        if self.config.e_ref_max is None: ss += \"\"\n",
    "        else: ss += \"_e_ref_max_{}\".format(energy_unit_format(self.config.e_ref_max).replace(' ', ''))\n",
    "        return ss\n",
    "    \n",
    "    def create_analysis_path(self): \n",
    "        \"\"\" ... \"\"\"\n",
    "        return Path(f\"analysis_counterparts/{self.create_analysis_name()}\")\n",
    "\n",
    "    def write_datasets(self, overwrite=True, path_file=None):\n",
    "        \"\"\"Write Datasets and Models to YAML file.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            overwrite : bool, optional\n",
    "                Overwrite existing file. Default is True.  \n",
    "            \"\"\"\n",
    "        \n",
    "        if path_file is None:\n",
    "            path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "        write_datasets(self.datasets, path_file, overwrite)\n",
    "    \n",
    "    def read_datasets(self, path_file=None):\n",
    "        \"\"\"Read Datasets and Models from YAML file.\"\"\"\n",
    "\n",
    "        if path_file is None:\n",
    "            path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "        return read_datasets(path_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ff9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTAObservationAnalysis:\n",
    "    \"\"\"Config-driven high level analysis interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `~gammapy.analysis.counterparts.CTAObservationAnalysisConfig`\n",
    "        Configuration options following `CTAObservationAnalysisConfig` schema.\n",
    "    \"\"\"\n",
    "    all = []\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.dataset_onoff = None\n",
    "        self.wstat = None\n",
    "        self.sens = None\n",
    "        self.sensitivity_table = None\n",
    "        self.fit_result_params = None \n",
    "        self.fit_result_joint = None\n",
    "        self.fpe = None\n",
    "        self.flux_points = None\n",
    "        \n",
    "\n",
    "        CTAObservationAnalysis.all.append(self)\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Analysis configuration as an `~feupy.analysis.CTAObservationAnalysisConfig` object.\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, CTAObservationAnalysisConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be CTAObservationAnalysisConfig\")\n",
    "            \n",
    "#     def run(self):\n",
    "#         self._make_energy_axes()\n",
    "#         self._get_dict_roi()\n",
    "#         self._get_df_roi()\n",
    "        \n",
    "#     def _make_energy_axes(self):\n",
    "        \n",
    "#         \"\"\"\n",
    "#         Select a catalog subset (only sources within a region of interest)\n",
    "#         \"\"\"\n",
    "\n",
    "#         datasets = Datasets() # global datasets object\n",
    "#         models = Models()  # global models object\n",
    "#         sources = [] # global sources object\n",
    "#         pulsars = [] # global pulsars object\n",
    "#         n_sources = 0 # number of sources\n",
    "#         n_flux_points = 0 # number of flux points tables\n",
    "        \n",
    "#         for catalog in self.catalogs:\n",
    "#             cat_tag = catalog.tag\n",
    "#             for source in catalog:\n",
    "#                 n_sources += 1   \n",
    "#                 source_name = source.name            \n",
    "#                 if cat_tag == PULSARTAG:\n",
    "#                     pass\n",
    "#                 else:\n",
    "#                     try:\n",
    "#                         flux_points = source.flux_points\n",
    "\n",
    "#                         spectral_model = source.spectral_model()\n",
    "#                         spectral_model_tag = spectral_model.tag[1]\n",
    "\n",
    "#                         if cat_tag == 'gamma-cat' or cat_tag == 'hgps':\n",
    "#                             dataset_name = f'{source_name}: {cat_tag}'\n",
    "#                         else: dataset_name = source_name\n",
    "\n",
    "#                         file_name = name_to_txt(dataset_name)\n",
    "\n",
    "#                         model = SkyModel(\n",
    "#                             name=f\"{file_name}_{spectral_model_tag}\",\n",
    "#                             spectral_model=spectral_model,\n",
    "#                             datasets_names=dataset_name\n",
    "#                         )\n",
    "\n",
    "#                         dataset = FluxPointsDataset(\n",
    "#                             models=model,\n",
    "#                             data=flux_points, \n",
    "#                             name=dataset_name   \n",
    "#                         )\n",
    "\n",
    "#                         if any([self.config.e_ref_min !=  None, self.config.e_ref_max !=  None]):\n",
    "#                             dataset = cut_energy_table_fp(dataset, self.config.e_ref_min, self.config.e_ref_max) \n",
    "\n",
    "#                         n_flux_points += 1\n",
    "#                         models.append(model)  # Add the model to models()\n",
    "#                         datasets.append(dataset)\n",
    "#                         sources.append(source)\n",
    "#                     except Exception as error:\n",
    "#                         # By this way we can know about the type of error occurring\n",
    "#                         print(f'The error is: ({source_name}) {error}') \n",
    "\n",
    "#         datasets.models = models\n",
    "#         self.datasets = datasets\n",
    "#         self.models = models\n",
    "#         self.sources = sources\n",
    "#         print(f\"Total number of gammapy sources: {len(self.sources)}\")\n",
    "#         print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "#         print(f\"Total number of pulsars: {len(self.pulsars)}\")\n",
    "             \n",
    "#     def _get_dict_roi(self):\n",
    "#         _dict_roi = {}\n",
    "\n",
    "#         roi_pos = self.config.roi.target.position \n",
    "#         radius_roi = self.config.roi.radius \n",
    "\n",
    "#         _sources = self.sources.copy()\n",
    "#         _sources.extend(self.pulsars)\n",
    "#         for index, source in enumerate(_sources):\n",
    "#             source_pos = source.position\n",
    "#             sep = source.position.separation(roi_pos).deg\n",
    "#             if index < len(self.datasets):\n",
    "#                 name = self.datasets[index].name\n",
    "#             else: name = source.name\n",
    "#             _dict_roi[name] = {\n",
    "#                 'position': source_pos,\n",
    "#                 'separation':sep\n",
    "#             }\n",
    "\n",
    "#         self.dict_roi = _dict_roi\n",
    "        \n",
    "#     def _get_df_roi(self):\n",
    "#         _dict = self.dict_roi\n",
    "\n",
    "#         df = pd.DataFrame()\n",
    "#         df[\"Source name\"] = _dict.keys()\n",
    "#         df_ra = []\n",
    "#         df_dec = []\n",
    "#         df_sep = []\n",
    "\n",
    "#         for index, name in enumerate(_dict.keys()):\n",
    "#             df_ra.append(_dict[name][\"position\"].ra.deg)\n",
    "#             df_dec.append(_dict[name][\"position\"].dec.deg)\n",
    "#             df_sep.append(_dict[name][\"separation\"])\n",
    "\n",
    "#         df[\"RA(deg)\"] = df_ra\n",
    "#         df[\"dec.(deg)\"] = df_dec\n",
    "#         df[\"Sep.(deg)\"] = df_sep\n",
    "#         self.df_roi = df\n",
    "        \n",
    "#     def create_analysis_name(self): \n",
    "#         \"\"\" ... \"\"\"\n",
    "#         ss = f\"{self.config.target.name}\"\n",
    "#         ss += \"_roi_{:.2f}\".format(self.config.roi.radius).replace(' ', '')\n",
    "#         if self.config.e_ref_min is None: ss += \"\"\n",
    "#         else: ss += \"_e_ref_min_{}\".format(energy_unit_format(self.config.e_ref_min).replace(' ', ''))\n",
    "#         if self.config.e_ref_max is None: ss += \"\"\n",
    "#         else: ss += \"_e_ref_max_{}\".format(energy_unit_format(self.config.e_ref_max).replace(' ', ''))\n",
    "#         return ss\n",
    "    \n",
    "#     def create_analysis_path(self): \n",
    "#         \"\"\" ... \"\"\"\n",
    "#         return Path(f\"analysis_counterparts/{self.create_analysis_name()}\")\n",
    "\n",
    "#     def write_datasets(self, overwrite=True, path_file=None):\n",
    "#         \"\"\"Write Datasets and Models to YAML file.\n",
    "\n",
    "#             Parameters\n",
    "#             ----------\n",
    "#             overwrite : bool, optional\n",
    "#                 Overwrite existing file. Default is True.  \n",
    "#             \"\"\"\n",
    "        \n",
    "#         if path_file is None:\n",
    "#             path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "#         write_datasets(self.datasets, path_file, overwrite)\n",
    "    \n",
    "#     def read_datasets(self, path_file=None):\n",
    "#         \"\"\"Read Datasets and Models from YAML file.\"\"\"\n",
    "\n",
    "#         if path_file is None:\n",
    "#             path_file = Path(f\"{self.create_analysis_path()}/datasets\")\n",
    "#         return read_datasets(path_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d81cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To save only the models\n",
    "# models_3fhl.write(\"3fhl_models.yaml\", overwrite=True)\n",
    "\n",
    "# # To save datasets and models\n",
    "# datasets.write(\n",
    "#     filename=\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\", overwrite=True\n",
    "# )\n",
    "\n",
    "# # To read only models\n",
    "# models = Models.read(\"3fhl_models.yaml\")\n",
    "# print(models)\n",
    "\n",
    "# # To read datasets with models\n",
    "# datasets_read = Datasets.read(\"datasets-gc.yaml\", filename_models=\"models_gc.yaml\")\n",
    "# print(datasets_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c1b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analysis_confg():\n",
    "    return CounterpartsAnalysisConfig(\n",
    "        \"LHAASO J1825-1326\", \n",
    "        276.45* u.Unit('deg'), \n",
    "        -13.45* u.Unit('deg'),\n",
    "        1* u.Unit('deg'),\n",
    "        1* u.Unit('erg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a982c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd551f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
