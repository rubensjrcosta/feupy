{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75dd3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Licensed under a 3-clause BSD style license - see LICENSE.rst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1144f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feupy.roi import ROI\n",
    "from feupy.target import Target\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.units import Quantity\n",
    "\n",
    "from gammapy.utils.units import energy_unit_format\n",
    "\n",
    "import logging\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acabd00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/born-again/Documents/GitHub/feupy/feupy/analysis\n"
     ]
    }
   ],
   "source": [
    "from feupy.utils.string_handling import name_to_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad862edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "PATH_ANALYSIS = Path(\"analysis\")\n",
    "PATH_ANALYSIS.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4513ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = [\"AnalysisConfig\", \"Analysis\"]\n",
    "\n",
    "# log = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# CONFIG_PATH = Path(__file__).resolve().parent / \"config\"\n",
    "# DOCS_FILE = CONFIG_PATH / \"docs.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9797e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to create a class:\n",
    "class AnalysisConfig:\n",
    "   # ADD others parameters\n",
    "   \n",
    "    # color=\"red\" # The color of the flux ponts\n",
    "    all=[]\n",
    "    @u.quantity_input(pos_ra=u.deg, pos_dec=u.deg, radius=u.deg, e_ref_min=u.eV, e_ref_max=u.eV)\n",
    "    def __init__(self, target_name: str, pos_ra, pos_dec, radius, e_ref_min=None, e_ref_max=None, catalogs_roi=None):\n",
    "       # Run validations to the received arguments\n",
    "        assert  0 <= pos_ra.value <= 360, f\"Right Ascension {pos_ra} is not in the range: (0,360) deg!\"\n",
    "        assert -90 <= pos_dec.value <= 90, f\"Declination {pos_dec} is not in the range: (-90,90) deg!\"\n",
    "\n",
    "        # Assign to self object\n",
    "        self.__target_name=target_name\n",
    "        self.position=SkyCoord(pos_ra, pos_dec) \n",
    "        self.radius=radius\n",
    "        if e_ref_min is not None:\n",
    "            self.e_ref_min=Quantity(e_ref_min, \"TeV\")\n",
    "        else: self.e_ref_min=e_ref_min\n",
    "        if e_ref_max is not None:\n",
    "            self.e_ref_max=Quantity(e_ref_max, \"TeV\")\n",
    "        else: self.e_ref_max=e_ref_max\n",
    "        self.energy_range=[self.e_ref_min, self.e_ref_max]\n",
    "        self.target=Target(self.__target_name, self.position.ra, self.position.dec)\n",
    "        self.roi=ROI(self.__target_name, self.position.ra, self.position.dec, self.radius)\n",
    "#         self.catalogs_roi=get_catalogs(self.roi)\n",
    "        \n",
    "        # Actions to execute\n",
    "        AnalysisConfig.all.append(self)\n",
    "    \n",
    "    @property\n",
    "    # Property Decorator=Read-Only Attribute\n",
    "    def info(self):\n",
    "        info={}\n",
    "        info[\"target_name\"]=self.target_name\n",
    "        info[\"position\"]=self.position\n",
    "        info[\"radius\"]=self.radius\n",
    "        info[\"energy_range\"]=self.energy_range\n",
    "        return info    \n",
    "    \n",
    "    @property\n",
    "    def target_name(self):\n",
    "        return self.__target_name\n",
    "\n",
    "    #     @name.setter\n",
    "    #     def name(self, value):\n",
    "    #         if len(value) > 15:\n",
    "    #             raise Exception(\"The name is too long!\")\n",
    "    #         else:\n",
    "    #             self.__name=value\n",
    "\n",
    "    @staticmethod\n",
    "    def is_integer(num):\n",
    "       # We will count out the floats that are point zero\n",
    "       # For i.e: 5.0, 10.0\n",
    "        if isinstance(num, float):\n",
    "           # Count out the floats that are point zero\n",
    "           return num.is_integer()\n",
    "        elif isinstance(num, int):\n",
    "            return True\n",
    "        else: return False\n",
    "\n",
    "    def __repr__(self):        \n",
    "        ss = f\"{self.__class__.__name__}(\"\n",
    "        ss += f\"target_name='{self.__target_name}', \"\n",
    "        ss += \"pos_ra={}*u.Unit('{}'), \".format(self.position.ra.value, self.position.ra.unit)\n",
    "        ss += \"pos_dec={}*u.Unit('{}'), \".format(self.position.dec.value, self.position.dec.unit)\n",
    "        ss += \"radius={}*u.Unit('{}'), \".format(self.radius.value, self.radius.unit)\n",
    "        if self.e_ref_min is None: ss += \"e_ref_min=None, \"\n",
    "        else: ss += \"e_ref_min=Quantity('{}'), \".format(energy_unit_format(self.e_ref_min).replace(' ', ''))\n",
    "        if self.e_ref_max is None: ss += \"e_ref_max=None)\"\n",
    "        else: ss += \"e_ref_max=Quantity('{}'))\".format(energy_unit_format(self.e_ref_max).replace(' ', ''))\n",
    "        return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710cc2b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee2acc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cli_run_analysis(filename, out, overwrite):\n",
    "#     \"\"\"Performs automated data reduction process.\"\"\"\n",
    "#     config = AnalysisConfig.read(filename)\n",
    "#     config.datasets.background.method = \"reflected\"\n",
    "#     analysis = Analysis(config)\n",
    "#     analysis.get_observations()\n",
    "#     analysis.get_datasets()\n",
    "#     analysis.datasets.write(out, overwrite=overwrite)\n",
    "#     log.info(f\"Datasets stored in {out} folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "010a1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_analysis_confg():\n",
    "    return AnalysisConfig(\n",
    "        \"LHAASO J1825-1326\", \n",
    "        276.45* u.Unit('deg'), \n",
    "        -13.45* u.Unit('deg'),\n",
    "        1* u.Unit('deg'),\n",
    "        1* u.Unit('erg')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a45704a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feupy.scripts import gammapy_catalogs \n",
    "from pathlib import Path\n",
    "\n",
    "from gammapy.utils.table import table_row_to_dict\n",
    "from feupy.catalog.pulsar.atnf import SourceCatalogATNF, SourceCatalogObjectATNF\n",
    "from feupy.catalog.lhaaso import SourceCatalogPublishNatureLHAASO\n",
    "from feupy.catalog.hawc import SourceCatalogExtraHAWC\n",
    "\n",
    "from gammapy.datasets import FluxPointsDataset\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy import units as u\n",
    "from gammapy.modeling.models import SkyModel, Models\n",
    "from gammapy.datasets import Datasets\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from gammapy.estimators import FluxPoints\n",
    "\n",
    "class Analysis:\n",
    "    \"\"\"Config-driven high level analysis interface.\n",
    "\n",
    "    It is initialized by default with a set of configuration parameters and values declared in\n",
    "    an internal high level interface model, though the user can also provide configuration\n",
    "    parameters passed as a nested dictionary at the moment of instantiation. In that case these\n",
    "    parameters will overwrite the default values of those present in the configuration file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    config : dict or `~gammapy.analysis.AnalysisConfig`\n",
    "        Configuration options following `AnalysisConfig` schema.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "#         self.config.set_logging()\n",
    "        self.catalogs = None\n",
    "        self.datasets = None\n",
    "        self.sources = None\n",
    "        self.models = None\n",
    "        self.pulsars = None\n",
    "        self.dict_roi = None\n",
    "        self.df_roi = None\n",
    "\n",
    "\n",
    "# #         self.fit = Fit()\n",
    "#         self.fit_result = None\n",
    "#         self.flux_points = None\n",
    "        \n",
    "    @property\n",
    "    def config(self):\n",
    "        \"\"\"Analysis configuration as an `~feupy.analysis.counterparts.AnalysisConfig` object.\"\"\"\n",
    "        return self._config\n",
    "\n",
    "    @config.setter\n",
    "    def config(self, value):\n",
    "        if isinstance(value, AnalysisConfig):\n",
    "            self._config = value\n",
    "        else:\n",
    "            raise TypeError(\"config must be AnalysisConfig.\")\n",
    "            \n",
    "    def run(self):\n",
    "        self._get_catalogs()\n",
    "        self._get_datasets()\n",
    "        self._get_pulsars()\n",
    "        self._get_dict_roi()\n",
    "        self._get_df_roi()\n",
    "        \n",
    "    def _get_catalogs(self):\n",
    "        _catalogs = []\n",
    "        catalogs_roi = []\n",
    "        \n",
    "        position = self.config.roi.position \n",
    "        radius = self.config.roi.radius \n",
    "\n",
    "        _catalogs.extend(gammapy_catalogs.load_all_catalogs())\n",
    "        _catalogs.append(SourceCatalogExtraHAWC())\n",
    "        _catalogs.append(SourceCatalogPublishNatureLHAASO())\n",
    "       \n",
    "\n",
    "        n_tot = len(_catalogs)\n",
    "        for catalog in _catalogs:        \n",
    "            # Selects only sources within the region of interest. \n",
    "            separation = position.separation(catalog.positions)\n",
    "\n",
    "            mask_roi = separation < radius\n",
    "\n",
    "            if len(catalog[mask_roi].table):\n",
    "                catalogs_roi.append(catalog[mask_roi])\n",
    "#                 n_roi += 1\n",
    "            else:\n",
    "                pass\n",
    "#               catalogs_roi_no.append(f\"{catalog.tag}: {catalog.description}\")\n",
    "        self.catalogs = catalogs_roi\n",
    "  \n",
    "    def _get_datasets(self):\n",
    "        \"\"\"\n",
    "        Select a catalog subset (only sources within a region of interest)\n",
    "        \"\"\"\n",
    "\n",
    "        datasets = Datasets() # global datasets object\n",
    "        models = Models()  # global models object\n",
    "        sources = [] # global sources object\n",
    "        n_sources = 0 # number of sources\n",
    "        n_flux_points = 0 # number of flux points tables\n",
    "    \n",
    "        for catalog in self.catalogs:\n",
    "            cat_tag = catalog.tag\n",
    "            for source in catalog:\n",
    "                n_sources+=1   \n",
    "                source_name = source.name            \n",
    "                try:\n",
    "                    flux_points = source.flux_points\n",
    "\n",
    "                    spectral_model = source.spectral_model()\n",
    "                    spectral_model_tag = spectral_model.tag[1]\n",
    "\n",
    "                    if cat_tag == 'gamma-cat' or cat_tag == 'hgps':\n",
    "                        dataset_name = f'{source_name}: {cat_tag}'\n",
    "                    else: dataset_name = source_name\n",
    "\n",
    "                    file_name = name_to_txt(dataset_name)\n",
    "\n",
    "                    model = SkyModel(\n",
    "                        name = f\"{file_name}_{spectral_model_tag}\",\n",
    "                        spectral_model = spectral_model,\n",
    "                        datasets_names=dataset_name\n",
    "                    )\n",
    "\n",
    "                    dataset = FluxPointsDataset(\n",
    "                        models = model,\n",
    "                        data = flux_points, \n",
    "                        name =  dataset_name   \n",
    "                    )\n",
    "\n",
    "                    if any([self.config.e_ref_min !=  None, self.config.e_ref_max !=  None]):\n",
    "                        dataset = self._cut_energy_flux_points(dataset)\n",
    "            \n",
    "                    n_flux_points+=1\n",
    "                    models.append(model)  # Add the model to models()\n",
    "\n",
    "                    sources.append(source)\n",
    "                    datasets.append(dataset)\n",
    "\n",
    "    #                 table = dataset.data.to_table(sed_type = cfg.sed_type_e2dnde, formatted = True)\n",
    "\n",
    "    #                 # Writes the flux points table in the csv/fits format\n",
    "    #                 utl.write_tables_csv(table, path_file, file_name)\n",
    "    #                 utl.write_tables_fits(table, path_file, file_name)\n",
    "\n",
    "                except Exception as error:\n",
    "                    # By this way we can know about the type of error occurring\n",
    "                    print(f'The error is: ({source_name}) {error}') \n",
    "\n",
    "        datasets.models = models\n",
    "        # To save datasets and models\n",
    "    #     utl.write_datasets_models(datasets,region_of_interest, datasets_name)\n",
    "\n",
    "        print(f\"Total number of Gammapy sources: {n_sources}\")\n",
    "        print(f\"Total number of flux points tables: {n_flux_points}\")\n",
    "        \n",
    "        self.sources = sources\n",
    "        self.datasets = datasets\n",
    "        self.models = models\n",
    "        \n",
    "    def _cut_energy_flux_points(self, dataset):\n",
    "        _datasets = Datasets()\n",
    "        e_ref_min = self.config.e_ref_min\n",
    "        e_ref_max = self.config.e_ref_max\n",
    "\n",
    "        flux_points = dataset.data\n",
    "        models = dataset.models[0]      \n",
    "        ds_name = dataset.name\n",
    "\n",
    "        if e_ref_min != None:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref >= e_ref_min:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points = FluxPoints.from_table(flux_points_mask)\n",
    "            print(e_ref)\n",
    "        if e_ref_max != None:\n",
    "            mask_energy = np.zeros(len(flux_points.to_table()), dtype=bool)\n",
    "\n",
    "            for m, e_ref in enumerate(flux_points.energy_ref):\n",
    "                if e_ref <= e_ref_max:\n",
    "                    mask_energy[m] = True\n",
    "\n",
    "            flux_points_mask = flux_points.to_table()[mask_energy]\n",
    "            flux_points = FluxPoints.from_table(flux_points_mask)     \n",
    "\n",
    "        return FluxPointsDataset(models = models, data = flux_points, name = ds_name)\n",
    "     \n",
    "    def _get_dict_roi(self):\n",
    "        _dict_roi = {}\n",
    "\n",
    "        roi_pos = self.config.roi.position \n",
    "        radius_roi = self.config.roi.radius \n",
    "\n",
    "        _sources = self.sources.copy()\n",
    "        _sources.extend(self.pulsars)\n",
    "        for index, source in enumerate(_sources):\n",
    "            source_pos = source.position\n",
    "            sep = source.position.separation(roi_pos).deg\n",
    "            if index < len(self.datasets):\n",
    "                name = self.datasets[index].name\n",
    "            else: name = source.name\n",
    "            _dict_roi[name] = {\n",
    "                'position': source_pos,\n",
    "                'separation':sep }\n",
    "\n",
    "        self.dict_roi = _dict_roi\n",
    "        \n",
    "    def _get_df_roi(self):\n",
    "        _dict = self.dict_roi\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df[\"Source name\"] = _dict.keys()\n",
    "        df_ra = []\n",
    "        df_dec = []\n",
    "        df_sep = []\n",
    "\n",
    "        for index, name in enumerate(_dict.keys()):\n",
    "            df_ra.append(_dict[name][\"position\"].ra.deg)\n",
    "            df_dec.append(_dict[name][\"position\"].dec.deg)\n",
    "            df_sep.append(_dict[name][\"separation\"])\n",
    "\n",
    "        df[\"RA(deg)\"] = df_ra\n",
    "        df[\"dec.(deg)\"] =df_dec\n",
    "        df[\"Sep.(deg)\"]= df_sep\n",
    "        self.df_roi = df\n",
    "        \n",
    "    # @u.quantity_input(pos_ra= u.deg,  pos_dec= u.deg, radius = u.deg)\n",
    "    def _get_pulsars(self, params=SourceCatalogATNF.PSR_PARAMS):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        position = self.config.roi.position \n",
    "        radius = self.config.roi.radius.value \n",
    "\n",
    "        dict_psr = []    \n",
    "    #     radius = roi.radius.value\n",
    "\n",
    "        # define circular search region\n",
    "        search_region = [str(position.ra), str(position.dec), radius]\n",
    "        # query ATNF catalog\n",
    "        psrs = SourceCatalogATNF().query(params = params, circular_boundary = search_region)\n",
    "\n",
    "        if len(psrs) == 0:\n",
    "            print('no PSR found!')\n",
    "        else:\n",
    "            # pulsars position in SkyCoord form\n",
    "            cpsrs = SkyCoord(\n",
    "                ra=psrs['RAJ'], \n",
    "                dec=psrs['DECJ'], \n",
    "                frame='icrs',            \n",
    "                unit=(u.hourangle, u.deg)\n",
    "            )\n",
    "            print(f'{len(psrs)} PSRs found!')\n",
    "\n",
    "            # calculate angular separation between pulsars and target\n",
    "            sep = cpsrs.separation(position)\n",
    "\n",
    "        for index, _table in enumerate(psrs.table):\n",
    "            _dict = table_row_to_dict(_table, make_quantity=True)\n",
    "            SourceCatalogObjectATNF.instantiate_from_ATNF([_dict])\n",
    "        self.pulsars = SourceCatalogObjectATNF.all\n",
    "        \n",
    "\n",
    "    def write_datasets_models(self, overwrite=True):\n",
    "        \"\"\"Write datasets and Models to YAML file.\n",
    "\n",
    "            Parameters\n",
    "            ----------\n",
    "            overwrite : bool, optional\n",
    "                Overwrite existing file. Default is True.\n",
    "            \"\"\"\n",
    "        path_file = Path(f\"{PATH_ANALYSIS}/datasets\")\n",
    "        path_file.mkdir(parents=True, exist_ok=True)\n",
    "        self.datasets.write(filename=f\"{path_file}/datasets.yaml\", filename_models=f\"{path_file}/models.yaml\", overwrite=overwrite)\n",
    "        \n",
    "        \n",
    "#     def read_datasets_models():\n",
    "#         path_file = Path(f\"{PATH_ANALYSIS}/datasets\")\n",
    "#         path_file.mkdir(parents=True, exist_ok=True)\n",
    "#         return Datasets.read(filename=f\"{path_file}/datasets.yaml\", filename_models=f\"{path_file}/models.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d81cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_confg = AnalysisConfig(\n",
    "#     \"LHAASO J1825-1326\", \n",
    "#     276.45* u.Unit('deg'), \n",
    "#     -13.45* u.Unit('deg'),\n",
    "#     1* u.Unit('deg'),\n",
    "#     1* u.Unit('erg')\n",
    "# )\n",
    "# analysis = Analysis(analysis_confg)\n",
    "# analysis.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077c1b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a982c10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcd551f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
